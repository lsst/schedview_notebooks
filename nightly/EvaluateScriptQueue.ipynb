{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74115f2c-5259-4f1d-a759-91b87f5bd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a range of dayobs values to search - \n",
    "day_obs_min = \"2024-11-16\"\n",
    "day_obs_max = \"2024-11-16\"\n",
    "\n",
    "# HEY NOTE: script salIndexes are reused (for different purposes) when scriptqueue is restarted\n",
    "# script salindex is not unique over all periods of time\n",
    "\n",
    "# also would like:\n",
    "# identifier for the scripts to replace or supplement script salIndex so that it's unique (hash for script)\n",
    "# Recording of hash for ts_config_ocs or for block itself --- this may be present in new obs_env (check manage_obs_env??)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac8228-7002-4ed1-b23f-c1563e5723e2",
   "metadata": {},
   "source": [
    "# EFD Scripts + Logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154e736-49e5-4eb4-9028-96489b848317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lsst.ts.xml.enums.GeneralState\n",
    "#help(ts_xml_enums)\n",
    "#import lsst.summit.utils\n",
    "#help(lsst.summit.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72ea7f-889c-40bb-8278-6720fbb80f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/lsst-ts/ts_xml/blob/develop/python/lsst/ts/xml/enums -- import would be better \n",
    "# Informational reference point .. \n",
    "import enum\n",
    "\n",
    "class GeneralState(enum.IntEnum):\n",
    "    \"\"\"CSC summaryState constants.\"\"\"\n",
    "\n",
    "    OFFLINE = 4\n",
    "    STANDBY = 5\n",
    "    DISABLED = 1\n",
    "    ENABLED = 2\n",
    "    FAULT = 3\n",
    "\n",
    "\n",
    "class ScriptProcessState(enum.IntEnum):\n",
    "    \"\"\"ScriptQueue script.processState event constants.\"\"\"\n",
    "\n",
    "    UNKNOWN = 0\n",
    "    LOADING = 1\n",
    "    CONFIGURED = 2\n",
    "    RUNNING = 3\n",
    "    DONE = 4\n",
    "    LOADFAILED = 5\n",
    "    CONFIGURE_FAILED = 6\n",
    "    TERMINATED = 7\n",
    "    CONFIGUREFAILED = 6  # deprecated alias for CONFIGURE_FAILED\n",
    "\n",
    "class ScriptState(enum.IntEnum):\n",
    "    \"\"\"ScriptState constants.\"\"\"\n",
    "\n",
    "    UNKNOWN = 0\n",
    "    UNCONFIGURED = 1\n",
    "    CONFIGURED = 2\n",
    "    RUNNING = 3\n",
    "    PAUSED = 4\n",
    "    ENDING = 5\n",
    "    STOPPING = 6\n",
    "    FAILING = 7\n",
    "    DONE = 8\n",
    "    STOPPED = 9\n",
    "    FAILED = 10\n",
    "    CONFIGURE_FAILED = 11\n",
    "\n",
    "# status_dict = dict((e.name, e.value) for e in GeneralState)\n",
    "# process_state_dict = dict((e.name, e.value) for e in ScriptProcessState)\n",
    "# script_state_dict = dict((e.name, e.value) for e in ScriptState)\n",
    "\n",
    "# display(f\"General state enum values: {status_dict}\")\n",
    "# display(f\"Script State enum values: {script_state_dict}\")\n",
    "# display(f\"Script Process State enum values: {process_state_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d21c3a-158c-4713-b704-b974d1f80644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import option_context\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from astropy.time import Time, TimeDelta\n",
    "import astropy.units as u\n",
    "\n",
    "from lsst_efd_client import EfdClient\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ed625-59a6-432a-b8b4-55d190c2509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the EFD \n",
    "\n",
    "# efd_client = EfdClient('summit_efd') \n",
    "efd_client = EfdClient('usdf_efd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff5dbc-0967-4de3-baed-b67be6be5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a range of dayobs values to search - \n",
    "t_start = Time(f\"{day_obs_min}T12:00:00\", format='isot', scale='utc')\n",
    "#t_start = t_start + TimeDelta(0.45, format='jd')\n",
    "#t_start = Time('2024-11-06T07:19:15.397500', format='isot', scale='utc') - TimeDelta(1/24, format='jd')\n",
    "\n",
    "t_end = Time(f\"{day_obs_max}T12:00:00\", format='isot', scale='utc') + TimeDelta(1, format='jd')\n",
    "#t_end = t_start + TimeDelta(2/24, format='jd')\n",
    "print(f\"Querying the EFD from {t_start.iso} to {t_end.iso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9f44b-5c40-49f0-834b-8b78ce785c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query any EFD topic for the timespan day_obs_min to day_obs_max, when you don't already know the fields\n",
    "# topic = lsst.sal.ScriptQueue.command_add\n",
    "# fields = await efd_client.get_fields(topic)\n",
    "# fields = [f for f in fields if 'private' not in f and f != 'name' and f!= \"duration\"]\n",
    "# dd = await efd_client.select_time_series(topic, fields, tstart, tend)\n",
    "# or top 5 .. \n",
    "# dd = await efd_client.select_top_n(topic, fields, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5803c3-9022-4605-99d1-e09ddfe8a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utilities \n",
    "def apply_enum(x, column, enumvals):\n",
    "    return enumvals(x[column]).name\n",
    "\n",
    "def convert_index_to_time(x):\n",
    "    return Time(x.name)\n",
    "\n",
    "def usdf_requests(API_ENDPOINT, params, try_dev=True):\n",
    "    # Try twice\n",
    "    response = requests.get(API_ENDPOINT, params)\n",
    "    if response.status_code != 200:\n",
    "        response = requests.get(API_ENDPOINT, params)\n",
    "    # Could dev as backup if still not working .. \n",
    "    # although this may not be the same content? \n",
    "    if try_dev:\n",
    "        if response.status_code != 200:\n",
    "            API_DEV = API_ENDPOINT.replace('usdf-rsp', 'usdf-rsp-dev')\n",
    "            # Try twice\n",
    "            response = requests.get(API_DEV, params)\n",
    "            if response.status_code != 200:\n",
    "                response = requests.get(API_DEV, params)\n",
    "    if response.status_code != 200:\n",
    "        err_string = f\"{API_ENDPOINT} \"\n",
    "        if try_dev: \n",
    "            err_string += f\"and {API_DEV}\"\n",
    "        err_string += \" unavailable.\"\n",
    "        print(err_string)\n",
    "        messages = []\n",
    "    else:\n",
    "        messages = response.json()\n",
    "    return pd.DataFrame(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a1a47-a657-4e98-8a99-79249844ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"timestamp\"] = Time(df[\"timestamp\"], format=\"unix_tai\", scale=\"utc\").datetime\n",
    "# df.set_index(\"timestamp\", inplace=True)\n",
    "# df.index = df.index.tz_localize(\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7db1c7-4bf5-4ad3-a941-4ada84b7fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within this time span, we need to split queries into blocks of continuous ScriptQueue uptime\n",
    "# If the ScriptQueue is restarted, the salIndexes will recycle. \n",
    "# Typically this should be on the order of once a day, but let's find the boundaries using the lsst.sal.ScriptQueue.logevent_summaryState topic\n",
    "topic = 'lsst.sal.ScriptQueue.logevent_summaryState'\n",
    "fields = ['salIndex', 'summaryState']\n",
    "dd = await efd_client.select_time_series(topic, fields, t_start, t_end)\n",
    "if len(dd) == 0:\n",
    "    tstops = []\n",
    "    tintervals = [[t_start, t_end]]\n",
    "else:\n",
    "    dd['state'] = dd.apply(apply_enum, args=['summaryState', GeneralState], axis=1)\n",
    "    dd['state_time'] = dd.apply(convert_index_to_time, axis=1)\n",
    "\n",
    "    tstops = dd.query('state == \"OFFLINE\"').state_time.values\n",
    "    #print(t_start, [e.isot for e in tstops], t_end)\n",
    "    if len(tstops) == 0:\n",
    "        tintervals = [[t_start, t_end]]\n",
    "    if len(tstops) > 0:\n",
    "        ts = tstops[0]\n",
    "        ts_next = ts + TimeDelta(1 * u.second)\n",
    "        tintervals = [[t_start, ts]]    \n",
    "        for ts in tstops[1:]:\n",
    "            tintervals.append([ts_next, ts])\n",
    "            ts_next = ts + TimeDelta(1 * u.second)\n",
    "        tintervals.append([ts_next, t_end])\n",
    "if len(tstops) == 0:\n",
    "    print(f\"Found 0 ScriptQueue OFFLINE events in the time period  {t_start} to {t_end}.\")\n",
    "else:\n",
    "    print(f\"Found {len(tstops)} ScriptQueue restarts in the time period {t_start} to {t_end}, so will query in {len(tstops)+1} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e1a46-fd1b-42d5-9710-d1ab9be43905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script queue --  this is where we need to find unique script salindexes in each time interval\n",
    "script_stream = []\n",
    "script_status = []\n",
    "for tinterval in tintervals:\n",
    "\n",
    "    # Script will find information about how scripts are configured. \n",
    "    # The description topic gives a more succinct human name to the scripts\n",
    "    topic = 'lsst.sal.Script.logevent_description'\n",
    "    fields = ['classname', 'description', 'salIndex']\n",
    "    scriptdescription = await efd_client.select_time_series(topic, fields, tinterval[0], tinterval[1])\n",
    "    scriptdescription.rename({'salIndex': 'script_salIndex'}, axis=1, inplace=True)\n",
    "    scriptdescription['add_time'] = scriptdescription.apply(convert_index_to_time, axis=1)\n",
    "    # This gets us more information about the script parameters, how they were configured\n",
    "    topic = 'lsst.sal.Script.command_configure'\n",
    "    fields = ['blockId', 'config',' executionId', 'salIndex']\n",
    "    fields = await efd_client.get_fields(topic)\n",
    "    fields = [f for f in fields if 'private' not in f]\n",
    "    # note blockId is only filled for JSON BLOCK activities\n",
    "    scriptconfig = await efd_client.select_time_series(topic, fields, tinterval[0], tinterval[1])\n",
    "    scriptconfig.rename({'salIndex': 'script_salIndex'}, axis=1, inplace=True)\n",
    "    scriptconfig[\"ts_configure_start\"] = scriptconfig.apply(convert_index_to_time, axis=1)\n",
    "\n",
    "    # Merge these together on script_salIndex which is unique over tinterval\n",
    "    # Find that configuration time - script add time is << 1 second for each script and < 1 second over a night\n",
    "    script_stream_t = pd.merge(scriptdescription, scriptconfig, on='script_salIndex', suffixes=['_d', '_r'])\n",
    "    # Append these into a list, which we will concat after looking at all tintervals\n",
    "    script_stream.append(script_stream_t)\n",
    "\n",
    "    # The status of each of these scripts is stored in scriptQueue.logevent_script\n",
    "    # so find the status of each of these scripts (this is status at individual stages).\n",
    "    topic = 'lsst.sal.ScriptQueue.logevent_script'\n",
    "    fields = await efd_client.get_fields(topic)\n",
    "    fields = ['blockId', 'path', 'processState', 'scriptState', 'salIndex', 'scriptSalIndex', \n",
    "             'timestampProcessStart', 'timestampConfigureStart', 'timestampConfigureEnd', 'timestampRunStart', 'timestampProcessEnd' ]\n",
    "    scripts = await efd_client.select_time_series(topic, fields, tinterval[0], tinterval[1])\n",
    "    scripts.rename({'scriptSalIndex': 'script_salIndex'}, axis=1, inplace=True)\n",
    "\n",
    "    # Group scripts on 'script_salIndex' to consolidate the information about its status stages\n",
    "    # Make a new copy which we will fill with the max script state (== final state, given enum)\n",
    "    # (new copy of this column so we don't have to deal with multi-indexes)\n",
    "    scripts['finalScriptState'] = scripts['scriptState']\n",
    "    script_status_t = scripts.groupby('script_salIndex').agg({'path': 'first', 'salIndex': 'max', \n",
    "                                                              'finalScriptState': 'max', 'scriptState': 'unique', \n",
    "                                                              'processState': 'unique', \n",
    "                                                              'timestampProcessStart': 'min', \n",
    "                                                              'timestampConfigureStart': 'min', \n",
    "                                                              'timestampConfigureEnd': 'max', \n",
    "                                                              'timestampRunStart': 'max', \n",
    "                                                              'timestampProcessEnd': 'max'}).sort_values(by='timestampProcessStart')\n",
    "    # Convert some columns from unix timestamps to iso for readability\n",
    "    # For some scripts, timestampConfigureStart is 0, but configure end is never 0\n",
    "    script_status_t['ts_configure_end'] = Time(script_status_t['timestampConfigureEnd'], format='unix_tai').utc.iso\n",
    "    # For some scripts, timestampRunStart is 0 (where nothing is run)\n",
    "    script_status_t['ts_run_start'] = Time(script_status_t['timestampRunStart'], format='unix_tai').utc.iso\n",
    "    script_status_t['ts_process_start'] = Time(script_status_t['timestampProcessStart'], format='unix_tai').utc.iso\n",
    "    script_status_t['ts_process_end'] = Time(script_status_t['timestampProcessEnd'], format='unix_tai').utc.iso\n",
    "    # Apply ScriptState enum for readability of final state\n",
    "    script_status_t['finalScriptState'] = script_status_t.apply(apply_enum, args=['finalScriptState', ScriptState], axis=1)\n",
    "\n",
    "    # Merge with script_stream so we get better descriptions and configuration information\n",
    "    dd = pd.merge(script_stream_t, script_status_t, left_on='script_salIndex', right_index=True, suffixes=['', '_s'])\n",
    "    script_status.append(dd)\n",
    "    print(\"#info - script-status\", [e.iso for e in tinterval], len(script_status), len(dd))\n",
    "\n",
    "    \n",
    "script_stream = pd.concat(script_stream)  # this may not be very useful or interesting compared to script-status df \n",
    "script_status = pd.concat(script_status)\n",
    "\n",
    "# Create an index that will slot this into the proper place for runtime / image acquisition, etc\n",
    "def find_best_script_time(x):\n",
    "    # Try run start first\n",
    "    best_time = x.timestampRunStart\n",
    "    if best_time == 0:\n",
    "        best_time = x.timestampConfigureEnd\n",
    "    if best_time == 0:\n",
    "        best_time = x.timestampConfigureStart\n",
    "    if best_time == 0:\n",
    "        best_time = x.timestampProcessStart\n",
    "    return Time(best_time, format='unix_tai').utc.iso\n",
    "script_status.index = script_status.apply(find_best_script_time, axis=1)\n",
    "# Columns most interesting from script_status\n",
    "scols = ['classname', 'description', 'config', 'script_salIndex', 'salIndex', 'blockId', 'finalScriptState', 'scriptState', 'ts_process_start', 'ts_configure_end', 'ts_run_start', 'ts_process_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdbba1-7fa7-454e-a83d-ce64d8e31690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get error codes\n",
    "topics = await efd_client.get_topics()\n",
    "err_codes = [t for t in topics if 'errorCode' in t]\n",
    "\n",
    "# will leave these for now .. should check if they are reflected in logevent_errorCode\n",
    "err_topics = [t for t in topics if  'Error' in t] \n",
    "\n",
    "errs = []\n",
    "for topic in err_codes:\n",
    "    df = await efd_client.select_time_series(topic, ['errorCode', 'errorReport'], t_start, t_end)\n",
    "    if len(df) > 0:\n",
    "        df['topic'] = topic\n",
    "        errs += [df]\n",
    "if len(errs) > 0:\n",
    "    errs = pd.concat(errs).sort_index()\n",
    "    errs['time'] = Time(errs.index, scale='utc')\n",
    "    errs.set_index('time', inplace=True)\n",
    "    def strip_csc(x):\n",
    "        return x.topic.replace(\"lsst.sal\", \"\").replace(\"logevent_errorCode\", \"\").replace(\".\", \"\") + \"CSC error\"\n",
    "    errs['component'] = errs.apply(strip_csc, axis=1)\n",
    "    # Rename some columns to match narrative log columns\n",
    "    errs.rename({'errorCode': 'error_code', 'errorReport': 'message_text', 'topic': 'origin'}, axis=1, inplace=True)\n",
    "    # Add a salindex so we can color-code based on this as a \"source\"\n",
    "    errs['salIndex'] = 4\n",
    "\n",
    "print(f\"Found {len(errs)} error messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d3006-271a-4425-8efb-b6390a5ed087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "params = {\"is_human\" : \"either\",\n",
    "          \"is_valid\" : \"true\",\n",
    "          \"has_date_begin\" : True,\n",
    "          \"min_date_begin\" : t_start.to_datetime(),\n",
    "          \"max_date_begin\" : t_end.to_datetime(),\n",
    "          \"order_by\" : \"date_begin\",\n",
    "          \"limit\": 10000, \n",
    "         }\n",
    "\n",
    "API_ENDPOINT = \"https://usdf-rsp.slac.stanford.edu/narrativelog/messages\"\n",
    "\n",
    "messages = usdf_requests(API_ENDPOINT, params)\n",
    "\n",
    "if len(messages) > 0:\n",
    "    def strip_rns(x):\n",
    "        return x.message_text.replace(\"\\r\\n\", \"\\n\").replace(\"\\n\\n\", \"\\n\").rstrip(\"\\n\")\n",
    "    def make_time(x):\n",
    "        return Time(x['date_begin'], format='isot', scale='utc').iso\n",
    "    def clarify_log(x):\n",
    "        if x.components is None:\n",
    "            component = \"Log\"\n",
    "        else:\n",
    "            component = \"Log \" + \" \".join(x.components)\n",
    "        return component\n",
    "    # Strip excessive \\r\\n and \\n\\n from messages\n",
    "    messages['message_text'] = messages.apply(strip_rns, axis=1)\n",
    "    # Add a time index\n",
    "    messages['time'] = messages.apply(make_time, axis=1)\n",
    "    messages.set_index('time', inplace=True)\n",
    "    # Join the components and add \"Log\" explicitly\n",
    "    messages['component'] = messages.apply(clarify_log, axis=1)\n",
    "    # rename some columns to match error data\n",
    "    messages.rename({'time_lost_type': 'error_code', 'user_id': 'origin'}, axis=1, inplace=True)\n",
    "    # Add a salindex so we can color-code based on this as a \"source\"\n",
    "    messages['salIndex'] = 0\n",
    "\n",
    "print(f\"Found {len(messages)} messages in the narrative log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8458d9d-b7e8-44a3-a771-bd7aff30cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge narrative log messages and error messages\n",
    "\n",
    "ncols = ['component', 'origin', 'message_text', 'error_code', 'salIndex']\n",
    "\n",
    "narrative_and_errs = []\n",
    "if len(errs) > 0 and len(messages) > 0:\n",
    "    print(\"Joined narrative log and error messages\")\n",
    "    narrative_and_errs = pd.concat([errs, messages]).sort_index()\n",
    "\n",
    "elif len(errs) > 0:\n",
    "    print(\"Error messages only; narrative log empty\")\n",
    "    narrative_and_errs = errs\n",
    "\n",
    "elif len(messages) > 0:\n",
    "    print(\"Narrative log only; error messages empty\")\n",
    "    narrative_and_errs = messages\n",
    "\n",
    "# if len(joint) > 0:\n",
    "#     with option_context('display.max_colwidth', None):\n",
    "#         joint.style.set_properties(**{'text-align': 'left'})\n",
    "#         display(HTML(joint[jcols].style.set_properties(**{'text-align': 'left'}).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef4c636-e972-411b-bf49-363e8e86e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exposure information\n",
    "topic = 'lsst.sal.CCCamera.logevent_endOfImageTelemetry' \n",
    "fields = ['imageName', 'imageIndex', 'exposureTime', 'darkTime', 'measuredShutterOpenTime', 'additionalValues', 'timestampAcquisitionStart', 'timestampDateEnd', 'timestampDateObs']\n",
    "image_acquisition = await efd_client.select_time_series(topic, fields, t_start, t_end)\n",
    "image_acquisition['ts_process_start'] = Time(image_acquisition['timestampAcquisitionStart'], format='unix_tai').utc.iso\n",
    "image_acquisition['ts_process_end'] = Time(image_acquisition['timestampDateEnd'], format='unix_tai').utc.iso\n",
    "image_acquisition['ts_run_start'] = Time(image_acquisition['timestampDateObs'], format='unix_tai').utc.iso\n",
    "image_acquisition['salIndex'] = -1\n",
    "image_acquisition['script_salIndex'] = 0\n",
    "image_acquisition['finalStatus'] = \"Image Acquired\"\n",
    "def make_config_col_for_image(x):\n",
    "    return f\"exp {x.exposureTime} // dark {x.darkTime} // open {x.measuredShutterOpenTime} \"\n",
    "image_acquisition['config'] = image_acquisition.apply(make_config_col_for_image, axis=1)\n",
    "image_acquisition.index = image_acquisition['ts_process_start'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d951f2f-db3f-42a3-9853-0e1a5a11716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lsst.summit.utils import ConsDbClient\n",
    "# # Not sure of summit consdb access, just use USDF for now\n",
    "# os.environ[\"LSST_CONSDB_PQ_URL\"] = \"http://consdb-pq.consdb:8080/consdb\"\n",
    "# os.environ[\"no_proxy\"] += \",.consdb\"\n",
    "\n",
    "# day_obs_int_min = int(day_obs_min.replace('-', ''))\n",
    "# day_obs_int_max = int(day_obs_max.replace('-', ''))\n",
    "\n",
    "# # Use the ConsDB Client, and add a couple of tries \n",
    "# consdb = ConsDbClient()\n",
    "\n",
    "# instrument = 'lsstcomcam'\n",
    "# visit_query = f'''\n",
    "#     SELECT * \n",
    "#     FROM cdb_{instrument}.visit1\n",
    "#      WHERE day_obs >= {day_obs_int_min}\n",
    "#      and day_obs  <= {day_obs_int_max}\n",
    "# '''\n",
    "# try:\n",
    "#     visits = consdb.query(visit_query).to_pandas()\n",
    "# except requests.HTTPError or requests.JSONDecodeError:\n",
    "#     # Try twice\n",
    "#     visits = consdb.query(visit_query).to_pandas()\n",
    "    \n",
    "# visits.set_index('visit_id', inplace=True)\n",
    "# (Time(visits.query('exposure_name == \"CC_O_20241115_000347\"')['exp_midpt'].values[0], format='isot', scale='tai') - TimeDelta(15 * u.second)).utc.iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c936eb-1367-43cb-bf82-3c8056a6ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(image_acquisition)} exposures from the CCCamera endOfImageTelemetry\")\n",
    "\n",
    "# exposure log too\n",
    "min_dayobs_int = int(t_start.iso[0:10].replace('-', ''))\n",
    "max_dayobs_int = int(t_end.iso[0:10].replace('-', ''))\n",
    "params = {\"is_human\" : \"either\",\n",
    "          \"is_valid\" : \"true\",\n",
    "          \"min_day_obs\" : min_dayobs_int,\n",
    "          \"max_day_obs\" : max_dayobs_int,\n",
    "          \"limit\": 10000, \n",
    "         }\n",
    "\n",
    "API_ENDPOINT = \"https://usdf-rsp.slac.stanford.edu/exposurelog/messages\"\n",
    "\n",
    "exp_logs = usdf_requests(API_ENDPOINT, params)\n",
    "print(f\"Found {len(exp_logs)} messages in the exposure log\")\n",
    "\n",
    "# Add exposure log\n",
    "if len(exp_logs) > 0:\n",
    "    # Note that we don't have a time in the exposure log - just a visit id, to join against the image acquisition information\n",
    "    exp = pd.merge(image_acquisition, exp_logs, how='right', left_on='imageName', right_on='obs_id')\n",
    "    # Set the time for the exposure log just slightly after the image start time\n",
    "    exp_log_image_time = Time(exp['timestampAcquisitionStart'], format='unix_tai') + TimeDelta(0.01 * u.second)\n",
    "    exp_logs['img_time'] = exp_log_image_time.utc.iso\n",
    "    exp_logs.set_index('img_time', inplace=True)\n",
    "    exp_logs['salIndex'] = 0\n",
    "    exp_logs['script_salIndex'] = 0\n",
    "    # Rename some columns now so that we can consolidate them here\n",
    "    exp_logs.rename({'obs_id': 'imageName', 'user_id': 'config', 'message_text': 'additionalValues', 'exposure_flag': 'finalStatus'}, axis=1, inplace=True)\n",
    "    image_and_logs = pd.concat([image_acquisition, exp_logs]).sort_index()\n",
    "    print(\"Joined exposure and exposure log\")\n",
    "else:\n",
    "    image_and_logs = image_acquisition\n",
    "\n",
    "\n",
    "icols = ['imageName', 'additionalValues', 'exposureTime', 'darkTime', 'measuredShutterOpenTime', 'finalStatus', 'script_salIndex', 'salIndex', 'ts_process_start', 'ts_run_start', 'ts_process_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04269f6-005a-4186-a869-8155f765c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now rename columns so we can put these all into the same dataframe\n",
    "# goal columns : \n",
    "cols = ['time', 'name', 'description', 'config', 'script_salIndex', 'salIndex', 'finalStatus', 'ts_process_start', 'ts_configure_end', 'ts_run_start', 'ts_process_end'] \n",
    "\n",
    "# columns from scripts\n",
    "script_cols = ['classname', 'description', 'config', 'script_salIndex', 'salIndex', 'blockId', 'finalScriptState', 'scriptState', 'ts_process_start', 'ts_configure_end', 'ts_run_start', 'ts_process_end']\n",
    "script_status.rename({'classname': 'name', 'finalScriptState': 'finalStatus'}, axis=1, inplace=True)\n",
    "# columns from narrative and errors\n",
    "narrative_cols = ['component', 'origin', 'message_text', 'error_code', 'salIndex']\n",
    "narrative_and_errs.rename({'component': 'name', 'origin': 'config', 'message_text': 'description', 'error_code': 'script_salIndex'}, axis=1, inplace=True)\n",
    "narrative_and_errs['ts_process_start'] = narrative_and_errs.apply(convert_index_to_time, axis=1)\n",
    "# columns from images_and_logs\n",
    "image_cols = ['imageName', 'additionalValues', 'config', 'finalStatus', 'script_salIndex', 'salIndex', 'ts_process_start', 'ts_run_start', 'ts_process_end']\n",
    "image_and_logs.rename({'imageName': 'name', 'additionalValues' : 'description'}, axis=1, inplace=True) \n",
    "\n",
    "\n",
    "efd_and_messages = pd.concat([script_status, narrative_and_errs, image_and_logs]).sort_index()\n",
    "# Wrap description, which can may have long zero-space messages in the errors\n",
    "efd_and_messages['description'] = efd_and_messages['description'].str.wrap(100)\n",
    "# use an integer index, which makes it easier to pull up values plus avoids occasional failures of time uniqueness\n",
    "efd_and_messages.reset_index(drop=False, inplace=True)\n",
    "efd_and_messages.rename({'index': 'time'}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# DROP SOME MESSAGES\n",
    "print(\"Dropping CBP messages and error messages from ElectrometerCSC and TuneableLaserCSC\")\n",
    "efd_and_messages = efd_and_messages.query('~ (config.str.contains(\"component: CBP\") or config.str.contains(\"CBP,\"))')\n",
    "efd_and_messages = efd_and_messages.query('~ (name.str.contains(\"ElectrometerCSC error\") or name.str.contains(\"TunableLaserCSC error\"))')\n",
    "\n",
    "\n",
    "def highlight_salindex(s):\n",
    "    # Colors from https://medialab.github.io/iwanthue/\n",
    "    if s.salIndex == 0:     # narrative log\n",
    "        return ['background-color: #cf7ddc'] * len(s)\n",
    "    elif s.salIndex ==  4:  # error messages\n",
    "        return ['background-color: #9cb5d5'] * len(s)\n",
    "    elif s.salIndex == 1:   # simonyi queue\n",
    "        return ['background-color: #b4c546'] * len(s)\n",
    "    elif s.salIndex == 2:   # aux tel queue\n",
    "        return ['background-color: #bab980'] * len(s)\n",
    "    elif s.salIndex == 3:   # ocs queue\n",
    "        return ['background-color: #b2baad'] * len(s)\n",
    "    #elif s.salIndex == -1:  # image\n",
    "    #    return ['background-color: #b6ecf5'] * len(s)\n",
    "    else:\n",
    "        return [''] * len(s)\n",
    "\n",
    "print(f\"Total combined messages {len(efd_and_messages)}\")\n",
    "print(\"Color coding by salIndex (1/2/3 scriptqueue index) + data source (narrative or exposure log, or EFD logevent_errorCode messages)\")\n",
    "print('')\n",
    "\n",
    "with option_context('display.max_colwidth', 0):\n",
    "    display(HTML(efd_and_messages[cols].style.apply(highlight_salindex, axis=1).set_table_styles([dict(selector='th', props=[('text-align', 'left')])]).set_properties(**{'text-align': 'left'}).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d06396-e1a1-43bb-980d-0eb55abe2711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
