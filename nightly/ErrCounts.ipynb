{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0a113-c0f8-446a-acc6-bc1f24c5dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times square parameters, for when you don't run in times square. Nothing in this cell will be executed in times square.\n",
    "day_obs = \"20250922\"\n",
    "n_nights_prev = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e06755-fe95-4616-b426-0a77a3c46b50",
   "metadata": {},
   "source": [
    "# Fault counts per subsystem - {{ params.day_obs }} and previous {{ params.n_nnights_prev }} nights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230be501-a297-44ca-a205-949fb354d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getenv(\"EXTERNAL_INSTANCE_URL\") is not None:\n",
    "    print(\"updating rubin_nights\")\n",
    "    !pip install --user --upgrade git+https://github.com/lsst-sims/rubin_nights.git  --no-deps  > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fd306-17bd-4f6d-8b66-882dbb29005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import minimum necessary packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# For lots of colors use glasbey\n",
    "from colorcet import glasbey \n",
    "\n",
    "from astropy.time import Time, TimeDelta\n",
    "import astropy.units as u\n",
    "\n",
    "from rubin_nights import connections, scriptqueue\n",
    "import rubin_nights.dayobs_utils as rn_dayobs\n",
    "\n",
    "if 'usdf' in os.getenv(\"EXTERNAL_INSTANCE_URL\", \"\"):\n",
    "    os.environ[\"RUBIN_SIM_DATA_DIR\"] = \"/sdf/data/rubin/shared/rubin_sim_data\"\n",
    "\n",
    "# Hack for Lynne - but you can use your own token (outside of RSP)\n",
    "if os.getenv(\"EXTERNAL_INSTANCE_URL\") is None:\n",
    "    tokenfile = '/Users/lynnej/.lsst/usdf_rsp'\n",
    "    site = 'usdf'\n",
    "    #tokenfile = '/Users/lynnej/.lsst/summit_rsp'\n",
    "    #site = 'summit'\n",
    "else:\n",
    "    tokenfile = None\n",
    "    site = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def63ef1-27ee-411a-8c58-76ab5a09e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = connections.get_clients(tokenfile=tokenfile, site=site)\n",
    "\n",
    "# Could run this over all days or over a single day .. or per day and then add new days .. \n",
    "t_start = Time('2025-09-01T12:00:00', format='isot', scale='utc')\n",
    "t_end = Time('2025-09-22T12:00:00', format='isot', scale='utc')\n",
    "\n",
    "error_topics = [t.replace('lsst.sal.', '').replace('.logevent_errorCode', '') for t in endpoints['efd'].get_topics() if 'errorCode' in t]\n",
    "\n",
    "errors = scriptqueue.get_error_codes(t_start, t_end, endpoints['efd'])\n",
    "\n",
    "errors['day_obs_mjd'] = np.zeros(len(errors), float)\n",
    "errors['day_obs'] = np.zeros(len(errors), int)\n",
    "errors['day'] = np.empty(len(errors), str)\n",
    "def time_to_dayobs(x):\n",
    "    x.day_obs_mjd = int(np.floor(Time(x.name, scale='utc').mjd - 0.5))\n",
    "    x.day = Time(x.day_obs_mjd, format='mjd', scale='utc').iso[5:10]\n",
    "    x.day_obs = Time(x.day_obs_mjd, format='mjd', scale='utc').iso[0:10].replace('-', '')\n",
    "    return x\n",
    "    \n",
    "errors = errors.apply(time_to_dayobs, axis=1)\n",
    "\n",
    "\n",
    "print(len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e64421-9bbe-40bd-b6dc-559a34bb0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select day_obs, visit_id, obs_start, obs_start_mjd, obs_end_mjd, band, science_program, img_type from cdb_lsstcam.visit1 where day_obs >= 20250415\"\n",
    "# visits = endpoints['consdb'].query(query)\n",
    "\n",
    "# visits['time'] =  pd.to_datetime(visits.obs_start, format='mixed')\n",
    "# visits.set_index('time', inplace=True)\n",
    "# visits = visits.tz_localize('UTC')\n",
    "\n",
    "# visits['salIndex'] = -10\n",
    "\n",
    "# print(len(visits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261abbda-b7a4-4753-8f5d-c570da401767",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {}\n",
    "groups['EnvSys'] = ['DIMM', 'DREAM', 'EAS', 'ESS', 'EPM', 'HVAC', 'OCPS', 'Watcher', 'ATBuilding',]\n",
    "error_update = [t for t in error_topics if t not in groups['EnvSys']]\n",
    "groups['CalSys'] = ['CBP', 'LaserTracker', 'Electrometer', 'FiberSpectrograph', 'LEDProjector', 'LinearStage', 'TunableLaser', 'PMD', \n",
    "                   'ATWhiteLight', 'ATMonochromator', 'ATSpectrograph']\n",
    "error_update = [t for t in error_update if t not in groups['CalSys']]\n",
    "groups['Simonyi'] = [t for t in error_update if t.startswith(\"MT\")] + ['GIS', 'Scheduler', 'ScriptQueue', 'NewMTMount']\n",
    "error_update = [t for t in error_update if t not in groups['Simonyi']]\n",
    "groups['AuxTel'] = [t  for t in error_update if t.startswith(\"AT\")] + ['Scheduler', 'ScriptQueue']\n",
    "error_update = [t for t in error_update if t not in groups['AuxTel']]\n",
    "groups['Other'] = error_update\n",
    "#groups\n",
    "addname = \"CSC error\"\n",
    "for group in groups:\n",
    "    updated_names = [t + addname for t in groups[group]]\n",
    "    groups[group] = updated_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f82791-0bd5-4060-89c7-8965899ae1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or create a pivot table, to set up a 'dashboard' style count per day per CSC\n",
    "dayerrs = errors.groupby(['component', 'day']).agg({'component': 'count'})\n",
    "dayerrs = dayerrs.reset_index('day')\n",
    "dayerrs = dayerrs.pivot(columns=['day'], values='component')\n",
    "dayerrs = dayerrs.fillna(0)\n",
    "\n",
    "\n",
    "# We can limit the CSCs or dayobs displayed -- or sort\n",
    "ecounts = errors.groupby('component').count()['error_code'].sort_values(ascending=False)\n",
    "ecscs = list(ecounts.index)\n",
    "\n",
    "# Simply no-flags display .. \n",
    "# dayerrs.loc[ecscs].iloc[:, last_n:]\n",
    "\n",
    "# but we could also do some work with the pivot table to set up flags or color-codes ..\n",
    "\n",
    "# Calculate a rolling mean value for the number of errors per CSC per dayobs, over last 10 reported dayobs (window)\n",
    "# The need to have data available for a longer window here, means we needed to fetch more days in error codes above.\n",
    "mean = dayerrs.T.rolling(window=10, min_periods=1, closed='left').mean().T\n",
    "\n",
    "# And now we could compare any given day's errors to the average of the previous 10 days\n",
    "diff = dayerrs - mean\n",
    "diff = diff.fillna(0)\n",
    "\n",
    "# And let's pick out the last last_n days to display to user\n",
    "last_n = -30 #len(dayerrs) + 1\n",
    "#diff = diff.iloc[:, last_n:]\n",
    "\n",
    "\n",
    "# Then display the errors with a color-code by creating a styler based on the diff\n",
    "style_df = (\n",
    "        diff > 0.5        \n",
    ").replace({\n",
    "    True: 'background-color:pink',  # True Styles\n",
    "    False: ''                      # False Styles\n",
    "})\n",
    "\n",
    "# And then apply this style to each value in each row, in the day errors values\n",
    "for group in groups:\n",
    "    group_topics_with_errors = [t for t in groups[group] if t in dayerrs.index.values]\n",
    "    if len(group_topics_with_errors) > 0:\n",
    "        subset = dayerrs.loc[group_topics_with_errors]\n",
    "        # Calculate a rolling mean value for the number of errors per CSC per dayobs, over last 10 reported dayobs (window)\n",
    "        # The need to have data available for a longer window here, means we needed to fetch more days in error codes above.\n",
    "        mean = subset.T.rolling(window=10, min_periods=1, closed='left').mean().T\n",
    "    \n",
    "        # And now we could compare any given day's errors to the average of the previous 10 days\n",
    "        diff = subset - mean\n",
    "        diff = subset.fillna(0)\n",
    "        diff = diff.iloc[:, last_n:] #last_n:]\n",
    "\n",
    "        # Then display the errors with a color-code by creating a styler based on the diff\n",
    "        style_df = (\n",
    "                diff > 0.5        \n",
    "        ).replace({\n",
    "            True: 'background-color:pink',  # True Styles\n",
    "            False: ''                      # False Styles\n",
    "        })\n",
    "        #display(subset.iloc[:, last_n:].style.apply(lambda _: style_df, axis=None).format(precision=0))\n",
    "        display(subset.iloc[:, last_n:].style.apply(lambda _: style_df, axis=None).format(precision=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c118fa4-1629-492f-8369-d8341241c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also make a stacked histogram of number of errors per CSC per night\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Need to add final night for last (right) edge of last bin.\n",
    "dayobs_range = np.arange(errors.day_obs_mjd.min(), errors.day_obs_mjd.max() + 2, 1)\n",
    "\n",
    "# Show a subset of these days \n",
    "dayobs_range = dayobs_range[last_n-1:]\n",
    "\n",
    "day_obs_labels = [Time(do_mjd, scale='utc', format='mjd').isot[0:10] for do_mjd in dayobs_range]\n",
    "\n",
    "# Stacked histogram, so keep running bottom of where bottom of bar should be.\n",
    "stack_bottom = np.zeros(len(dayobs_range)-1)\n",
    "colors = glasbey \n",
    "#colors = tab20\n",
    "\n",
    "i = 0\n",
    "for ec in groups['Simonyi']:\n",
    "    q = errors.query('component == @ec')\n",
    "    if len(q) > 0:\n",
    "        c, b = np.histogram(q['day_obs_mjd'], bins=dayobs_range)\n",
    "        stack_bottom += c\n",
    "        plt.bar(dayobs_range[0:-1], c, bottom=stack_bottom-c, label=ec, color=glasbey[i])\n",
    "    i += 1\n",
    "\n",
    "_ = plt.xticks(rotation=90, ticks=dayobs_range[:-1], labels=day_obs_labels[:-1])\n",
    "_ = plt.xlabel(\"DayObs\", fontsize='x-large')\n",
    "_ = plt.ylabel(\"Number of errors\", fontsize='x-large')\n",
    "_ = plt.legend(loc=(1.01, 0.2))\n",
    "#_ = plt.ylim(0, 200)\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ff78b-1905-4557-b2e1-fa62f3703e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simonyi_errs = errors.query(\"\n",
    "\n",
    "#ve = pd.concat([visits, errors]).sort_index()\n",
    "# find error -> visits\n",
    "#error_to_image = np.where((ve[:-1]['salIndex'] > 0) and (ve[1:]['salIndex'] < 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadfc14-b996-4620-b5d8-57977f75a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image -> error\n",
    "im2err = np.where((ve[:-1]['salIndex'].values < 0 ) & (ve[1:]['salIndex'].values > 0))[0]\n",
    "im2err = np.sort(np.concatenate([im2err, im2err+1]))\n",
    "ve.iloc[im2err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44a6b85-61a6-4a53-886c-2481f4b0a5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
