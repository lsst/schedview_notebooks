{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1433594-d951-416a-bf43-3068e46f26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is only for setting example parameter defaults - gets replaced by sidecar.\n",
    "day_obs = \"2024-08-21\"\n",
    "#day_obs = \"Today\"\n",
    "telescope = \"AuxTel\"  \n",
    "#telescope = \"SimonyiTel\"\n",
    "instrument = \"latiss\"  \n",
    "#instrument = \"lsstcomcamsim\"\n",
    "salindex = 2\n",
    "#salindex = 3\n",
    "timezone = \"Chile/Continental\"\n",
    "#timezone = \"UTC\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac5b1f-b036-4213-ae6d-700dcad8a7a6",
   "metadata": {},
   "source": [
    "# Scheduler: Targets, Observations and ConsDB Visits for {{ params.day_obs }} - {{ params.telescope }}\n",
    "\n",
    "The Feature Based Scheduler requests `Targets` and completed observation scripts result in `Observations`. Data is tracked in the EFD.\n",
    "The Consdb reports acquired `Visits`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17629b1c-626e-417f-8bdc-20332107534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pylab as plt\n",
    "from cycler import cycler\n",
    "import colorcet as cc\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import datetime\n",
    "from astropy.time import Time, TimeDelta\n",
    "import astropy.units as u\n",
    "import astropy\n",
    "astropy.utils.iers.conf.iers_degraded_accuracy = 'ignore'\n",
    "\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "try:\n",
    "    tz = ZoneInfo(timezone)\n",
    "    tz_utc = ZoneInfo(\"UTC\")\n",
    "except ZoneInfoNotFoundError:\n",
    "    print(\"Timezone should be a string recognizable to `ZoneInfo`.\")\n",
    "    print(\"Using Chile/Continental (+UTC) backup.\")\n",
    "    tz = ZoneInfo(\"Chile/Continental\")\n",
    "    tz_utc = ZoneInfo(\"UTC\")\n",
    "\n",
    "from rubin_scheduler.site_models import Almanac\n",
    "from rubin_scheduler.utils import Site\n",
    "\n",
    "import requests\n",
    "import sqlalchemy\n",
    "from lsst_efd_client import EfdClient\n",
    "try:\n",
    "    from lsst.summit.utils import ConsDbClient\n",
    "    have_consdb = True\n",
    "except ImportError:\n",
    "    have_consdb = False\n",
    "\n",
    "# for scheduler snapshots\n",
    "from urllib.parse import urlparse\n",
    "from lsst.resources import ResourcePath\n",
    "\n",
    "\n",
    "# at USDF or at summit?\n",
    "if os.getenv(\"EXTERNAL_INSTANCE_URL\", \"\") == \"https://summit-lsp.lsst.codes\":\n",
    "    efd = 'summit_efd'\n",
    "else:\n",
    "    efd = 'usdf_efd'  \n",
    "    os.environ[\"RUBIN_SIM_DATA_DIR\"] = \"/sdf/data/rubin/shared/rubin_sim_data\"\n",
    "# Not sure of summit consdb access, just use USDF for now\n",
    "os.environ[\"LSST_CONSDB_PQ_URL\"] = \"http://consdb-pq.consdb:8080/consdb\"\n",
    "os.environ[\"no_proxy\"] += \",.consdb\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eda54a-f5fa-4f1a-9068-af721e185471",
   "metadata": {},
   "outputs": [],
   "source": [
    "if day_obs == \"Today\":\n",
    "    # Shift the 12hour offset following the definition of day_obs in https://sitcomtn-032.lsst.io/    \n",
    "    # Drop the hours, minutes, seconds to get the ISO formatted day_obs\n",
    "    day_obs = (Time.now() - TimeDelta(0.5, format='jd')).iso[:10]\n",
    "\n",
    "elif day_obs == \"Yesterday\":\n",
    "    # Shift the 12hour offset following the definition of day_obs in https://sitcomtn-032.lsst.io/\n",
    "    # Drop the hours, minutes, seconds to get the ISO fromatted day_obs\n",
    "    day_obs = (Time.now() - TimeDelta(1.5, format='jd')).iso[:10]\n",
    "\n",
    "else:\n",
    "    # test that day_obs is a proper day_obs\n",
    "    try:\n",
    "        test_day_obs = Time(f\"{day_obs}T12:00:00\", format='isot', scale='utc')\n",
    "    except ValueError:\n",
    "        msg = \"day_obs should be a date formatted as YYYY-MM-DD\"\n",
    "        raise ValueError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e9430-0899-4218-896b-d6083667d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_to_days = 1./60/24\n",
    "seconds_to_days = 1./60/60/24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e09c6b-ce0a-49bd-ae96-37f6dd12a2f1",
   "metadata": {},
   "source": [
    "## Almanac information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e75664-53f5-4748-83d4-479c1697db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "site = Site('LSST')\n",
    "almanac = Almanac()\n",
    "night_events = almanac.get_sunset_info(evening_date=day_obs, longitude=site.longitude_rad)\n",
    "sunset = Time(night_events['sunset'], format='mjd', scale='utc') \n",
    "sunrise = Time(night_events['sun_n12_rising'], format='mjd', scale='utc')\n",
    "survey_length = sunrise.mjd - sunset.mjd\n",
    "display(Markdown(f\"<strong>On {day_obs}:</strong>\"))\n",
    "print(f\"12-deg sunset at {sunset.iso} 12-deg sunrise at {sunrise.iso}, for a {survey_length * 24 :.2f} hour night\")\n",
    "moon_phase = almanac.get_sun_moon_positions(sunset.mjd)['moon_phase']\n",
    "print(f\"Moonrise is at {Time(night_events['moonrise'], format='mjd', scale='utc').iso}, moonset at {Time(night_events['moonset'], format='mjd', scale='utc').iso},\"\n",
    "      f\" with a phase of {moon_phase :.1f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e874bf79-c2b9-4f54-88aa-d194a5eb0a1e",
   "metadata": {},
   "source": [
    "## EFD information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e60d9-302e-4f41-8f32-f5f9b4511c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "efd_client = EfdClient(efd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae43f4a7-b2fb-41fa-8f33-b9d760d7dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scheduler could be set up before sunset.\n",
    "early_setup = sunset - TimeDelta(5*60*60, format='sec')\n",
    "# And the blocks could be added before sunset, but let's avoid some afternoon calibs\n",
    "early_block = sunset - TimeDelta(1*60*60, format='sec')\n",
    "\n",
    "# What versions of the Scheduler modules are being used\n",
    "display(Markdown(\"<strong>Versions</strong>\"))\n",
    "topic = 'lsst.sal.Scheduler.logevent_dependenciesVersions'\n",
    "fields = await efd_client.get_fields(topic)\n",
    "fields = [f for f in fields if \"private\" not in f]\n",
    "dd = await efd_client.select_time_series(topic, fields, early_setup, sunrise, index=salindex)\n",
    "display(dd)\n",
    "\n",
    "# How is the FBS and Scheduler configured \n",
    "display(Markdown(\"<strong>Configurations applied</strong>\"))\n",
    "topic = 'lsst.sal.Scheduler.logevent_configurationApplied'\n",
    "fields = await efd_client.get_fields(topic)\n",
    "dd = await efd_client.select_time_series(topic, fields, early_setup, sunrise, index=salindex)\n",
    "if len(dd) == 0:\n",
    "    print(f\"No scheduler configurations applied between {sunset.iso} and {sunrise.iso}\")\n",
    "else:\n",
    "    for i, row in dd[['configurations', 'schemaVersion', 'url']].iterrows():\n",
    "        print(i, row.configurations)\n",
    "        print(i, row.schemaVersion, row.url)\n",
    "print()\n",
    "\n",
    "# What other BLOCKS have been requested in this night (outside the FBS)\n",
    "display(Markdown(\"<strong>JSON BLOCKS</strong>\"))\n",
    "topic = 'lsst.sal.Scheduler.command_addBlock'\n",
    "fields = await efd_client.get_fields(topic)\n",
    "fields = [f for f in fields if 'private' not in f]\n",
    "dd = await efd_client.select_time_series(topic, fields, early_block, sunrise, index=salindex)\n",
    "if len(dd) == 0:\n",
    "    print(f\"No JSON BLOCKS added between {sunset.iso} and {sunrise.iso}\")\n",
    "else:\n",
    "    display(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb48b5-6645-447c-a714-ead55c6ba536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch requested targets\n",
    "topic = 'lsst.sal.Scheduler.logevent_target'\n",
    "all_fields = await efd_client.get_fields(topic)\n",
    "#print(all_fields)\n",
    "targets = await efd_client.select_time_series(topic, all_fields, sunset, sunrise, index=salindex)\n",
    "\n",
    "# When estimating obsmjd expected from target -- include the previous\n",
    "# exposure time or not? (in theory, should. in practice, queue is busy so not including it can be helpful).\n",
    "include_prev_exptime = False\n",
    "\n",
    "def demangle_note(x):    \n",
    "    # remove _expnum\n",
    "    x.target = copy.deepcopy(x.note)\n",
    "    if \"IM\" in x.note:\n",
    "        x.note = x.note.split(\":\")[1].split(\"_\")[0]\n",
    "    if 'spec' in x.note:\n",
    "        x.note = 'HD' + x.note.split('HD')[-1]\n",
    "    return x\n",
    "\n",
    "if len(targets) == 0:\n",
    "    print(f\"On night {day_obs} {telescope} recorded {len(targets)} target log events.\")\n",
    "    print(f\"This was for times between {sunset.iso}, {sunrise.iso}\")\n",
    "\n",
    "    # debug help -- \n",
    "    targets = await efd_client.select_top_n(topic, all_fields, 2, index=salindex)\n",
    "    print(\"The most recent targets were recorded were:\")\n",
    "    display(targets[['SchedulerID', 'airmass', 'ra', 'decl', 'skyAngle', 'exposureTimes0', 'skyBrightness', 'slewTime', 'note', 'salIndex']])\n",
    "\n",
    "else:\n",
    "\n",
    "    # target timestamp in EFD = time that the target is pushed to scriptqueue\n",
    "    # this should be at the start of the previous observation\n",
    "    targets[\"target_time\"] = targets.index.copy()\n",
    "    targets[\"target_mjd\"] = Time(targets.index).mjd\n",
    "    # estimate what time this target should be observed (start of observation)\n",
    "    # == target_time + previous exposure time (?) + slew time\n",
    "    cols = [c for c in targets if 'exposureTimes' in c]\n",
    "    targets['total_exptime'] = targets[cols].sum(axis=1)\n",
    "    \n",
    "    # Try to fix the exposure times, to match JSON values\n",
    "    total_exptime = targets['total_exptime'].values\n",
    "    for i, (idx, row) in enumerate(targets.iterrows()):\n",
    "        if 'spec' in row.note:\n",
    "            total_exptime[i] = 495\n",
    "        if 'bright' in row.note:\n",
    "            total_exptime[i] = 152\n",
    "        if 'cwfs' in row.note:\n",
    "            # Honestly, we can't really tell with cwfs because\n",
    "            # there seem to be highly variable sequences\n",
    "            total_exptime[i] = 8 * 30            \n",
    "    #targets['total_exptime'] = total_exptime\n",
    "\n",
    "    previous_exposure_time = np.concatenate([np.array([0]), targets['total_exptime'][:-1]])\n",
    "    # The target is supposed to be issued to the EFD when it hits the top of the scriptqueue \n",
    "    # which is supposed to be when the previous observation starts ... however\n",
    "    # an observation having many scripts may mean it doesn't hit the top of the scriptqueue then.\n",
    "    # (so this is probably more like a range of target.mjd + slewtime --- target + slewtime + previous exposure\n",
    "    targets[\"previous_exptime\"] = previous_exposure_time\n",
    "    targets[\"target_obsmjd\"] = Time(targets.index).mjd  + (targets['slewTime'])*seconds_to_days \n",
    "    if include_prev_exptime:\n",
    "        targets[\"target_obsmjd\"] += (targets[\"previous_exptime\"])*seconds_to_days\n",
    "    \n",
    "    # mangle the note again \n",
    "    targets['orig_note'] = targets.note.copy()\n",
    "    targets = targets.apply(demangle_note, axis=1)\n",
    "    \n",
    "    targets = targets.sort_values(by='target_obsmjd')\n",
    "    targets['target_id'] = np.arange(0, len(targets), 1)\n",
    "    targets = targets.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"On night {day_obs} {telescope} recorded {len(targets)} target log events for \\n{targets.note.unique()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dc7ca-4e42-4a70-bb92-b5c875634fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations are the completed observation script .. to be compared with visits from the consdb\n",
    "\n",
    "topic = 'lsst.sal.Scheduler.logevent_observation'\n",
    "all_fields = await efd_client.get_fields(topic)\n",
    "obs = await efd_client.select_time_series(topic, all_fields, sunset, sunrise, index=salindex)\n",
    "\n",
    "if len(obs) == 0:\n",
    "    print(f\"On night {day_obs} {telescope} recorded {len(obs)} observation log events.\")\n",
    "\n",
    "else:\n",
    "    # timestamp is the time of successful end of observation/JSON block\n",
    "    obs['obs_time'] = obs.index.copy()\n",
    "    # Try to fix incorrect exposure times\n",
    "    #exptimes = obs['exptime'].values\n",
    "    #exptimes = np.where(exptimes == 360, 152, exptimes)\n",
    "    #exptimes = np.where(exptimes == 420, 495, exptimes)\n",
    "    #obs['exptime'] = exptimes\n",
    "\n",
    "    # obs time - exposure time should be start of observation (if exposure time is correct)\n",
    "    obs['obs_obsmjd'] = Time(obs.index).mjd - (obs['exptime'] * seconds_to_days)\n",
    "    \n",
    "    obs = obs.sort_values(by='obs_obsmjd')\n",
    "    obs['obs_id'] = np.arange(0, len(obs), 1)\n",
    "    obs = obs.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"On night {day_obs} {telescope} recorded {len(obs)} observation log events.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca4e886-e93c-47d9-b724-d96a77ac52f2",
   "metadata": {},
   "source": [
    "## Matching targets to observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea280c-c029-4689-8f2f-70c26f503a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_obs_and_targets(obs, targets):\n",
    "    # Check targets -> observations\n",
    "    target_to_obs_match = np.zeros(len(targets), int)\n",
    "    obs_to_target_match = np.zeros(len(obs), int)\n",
    "    \n",
    "    print(\"Matching observations against targets\")\n",
    "    count = 0\n",
    "    for i, (ri, t) in enumerate(targets.iterrows()):\n",
    "        # Match obs_mjd, ra/dec/filter from target+observation\n",
    "        # the target.obs_mjd may overestimate actual mjd by ~ previous exposure\n",
    "        # if slewtime is inaccurate, target_obs.mjd may be inaccurate\n",
    "        # if visit includes JSON BLOCK with many steps, could be delays \n",
    "        # so that obs_obsmjd is later than reality\n",
    "        # some targets may never get completed observations\n",
    "        slew_error = 2.0 * minutes_to_days\n",
    "        target_error = t.previous_exptime\n",
    "        # prevents matching to \"wrong version\" of target\n",
    "        X = 28 * minutes_to_days\n",
    "        match = np.where((np.abs(t.target_obsmjd - obs.obs_obsmjd) < target_error + slew_error) # close in time\n",
    "                         & ((obs.obs_obsmjd - t.target_obsmjd) <= X) # not more than X\n",
    "                         & (t.ra == obs.ra) \n",
    "                         & (t.decl == obs.decl) \n",
    "                         & (t['filter'] == obs['filter'])\n",
    "                         & (obs_to_target_match == 0))[0]\n",
    "        if len(match) == 0:\n",
    "            print(f'no obs match for target {t.target_id}')\n",
    "            count += 1\n",
    "            target_to_obs_match[i] = -1\n",
    "        else:\n",
    "            # Consider target to have found the best match \n",
    "            # in the first (soonest) of 'match'\n",
    "            idx = match[0]\n",
    "            target_to_obs_match[i] = obs.iloc[idx]['obs_id']\n",
    "            # And consider observation to have found a match\n",
    "            obs_to_target_match[idx] = t['target_id']\n",
    "\n",
    "    obs['target_id'] = np.array(obs_to_target_match)\n",
    "    targets['obs_id'] = np.array(target_to_obs_match)\n",
    "    \n",
    "    print(f'failed to match {count} targets to observations')\n",
    "    print(f'compare to {len(targets) - len(obs)} expected difference')\n",
    "    return obs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8df77e-41bc-4eca-beb3-d3b6acab871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(obs) > 0:\n",
    "    obs, targets = match_obs_and_targets(obs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1665de7-1903-4c50-867d-540b03b6a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(obs) > 0:\n",
    "    # Join targets + obs\n",
    "    jj = obs.join(targets, on='target_id', lsuffix='_o', rsuffix='_t')\n",
    "    jj = jj.sort_values(by='obs_obsmjd')\n",
    "    \n",
    "    jj['delta_obs'] = np.concatenate([np.array([0]), np.diff(jj['obs_obsmjd'])/minutes_to_days]) # minutes -- should be close to expected overhead\n",
    "    jj['delta_request'] = (jj['obs_obsmjd'] - jj['target_obsmjd']) / minutes_to_days # minutes  -- should be close to 0\n",
    "    jj['expected_overhead'] = (jj['previous_exptime']+ jj['slewTime'])/60 # minutes\n",
    "else:\n",
    "    jj = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b422b44-bdef-4e2f-81ea-569365a07c24",
   "metadata": {},
   "source": [
    "## Comparing overheads\n",
    "\n",
    "Comparing the expected overhead from the calculated slewtime and exposure time to the actual time recorded between observation events (where matched to targets). \n",
    "Using this to identify longer than predicted overheads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e407e-08c6-4264-838b-18fa19901b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(jj) > 0:\n",
    "    _ = plt.hist(jj['delta_obs'], bins=np.arange(-2, 25, 0.5), alpha=0.4, histtype='bar', label='delta obs')\n",
    "    _ = plt.hist(jj['expected_overhead'], bins=np.arange(-2, 25, 0.5), alpha=0.3, histtype='bar', label='calc overhead between obs')\n",
    "    #_ = plt.hist(jj['delta_request'], bins=np.arange(-2, 25, 0.5), alpha=0.3, histtype='bar', label='delta expected obs time')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c3fd5-2621-400a-a148-938bf6fa2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where did the time between observations just take longer than expected \n",
    "# delta obs compared to (slewTime + exptime) BUT sheduler target estimate was correct\n",
    "\n",
    "overhead_error = 6\n",
    "\n",
    "if len(jj)>0: \n",
    "    overheads = np.where(np.abs(jj.delta_obs - jj.expected_overhead) > overhead_error)\n",
    "    \n",
    "    breaks = []\n",
    "    for b in overheads[0]:\n",
    "        b_start = jj.iloc[b-1]['obs_obsmjd'] # + jj.iloc[b-1]['exptime']/60/60/24\n",
    "        b_end = jj.iloc[b]['obs_obsmjd'] #- jj.iloc[b]['slewTime']/60/60/24\n",
    "        # look for cwfs sweeps around the break, as they seem to mess with timings\n",
    "        b_min = np.max([b-1, 0])\n",
    "        b_max = np.min([b+1, len(jj)-1])\n",
    "        check_for_cwfs = jj.iloc[b_min:b_max+1].query(\"note == 'cwfs'\")\n",
    "        if len(check_for_cwfs) > 0:\n",
    "            # We can probably disregard many of these, for now, as cwfs sweeps \n",
    "            # seem to mess with queue order and have variable length\n",
    "            # but also, when we come out of \"break\", a real fault will tend to have a cwfs sequence.\n",
    "            # So try to distinguish these real breaks from timing problems\n",
    "            if b_end - b_start >= 10:\n",
    "                breaks.append([b_start, b_end])\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            breaks.append([b_start, b_end])\n",
    "\n",
    "    # should also highlight anywhere there are more than one failed target in a row\n",
    "    t = targets.query('obs_id == -1')\n",
    "    i = 1\n",
    "    break_start = t['target_obsmjd'].iloc[0]\n",
    "    while i < len(t):\n",
    "        if (t['target_id'].iloc[i] - t['target_id'].iloc[i-1] > 1) | (i == len(t) - 1):\n",
    "            # We skipped more than one target id, so passed the end of the break\n",
    "            break_end = t['target_obsmjd'].iloc[i-1]\n",
    "            breaks.append([break_start, break_end])\n",
    "            break_start = t['target_obsmjd'].iloc[i]\n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    print(f\"Looks like there are about {len(overheads[0])} breaks where overheads and exposure times don't match, of which {len(breaks)} don't involve CWFS observations\")\n",
    "    print(\"Note: there are some not-well-understood issues that could look like a 'break' when there isn't actually a break .. it's a WIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e70331-15e8-4583-8926-d5b2fb9c5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(jj) > 0:\n",
    "    plt.figure()\n",
    "    \n",
    "    eps = 1\n",
    "    for note in jj.note.unique():\n",
    "        j = jj.query('note == @note')\n",
    "        plt.plot(j.delta_obs, j.expected_overhead, '.', label=note)\n",
    "    j = jj.iloc[overheads]\n",
    "    plt.plot(j.delta_obs, j.expected_overhead, 'o',\n",
    "             markersize=10, color='k', markerfacecolor='none', label='Big Overhead')\n",
    "    plt.legend(loc=(1.01, 0.5))\n",
    "    for exptime in jj.exptime.unique():\n",
    "        plt.axhline(exptime/60, color='gray', linestyle=':', alpha=0.6)\n",
    "    \n",
    "    x = np.arange(0, 60)\n",
    "    plt.plot(x, x, 'r:')\n",
    "    plt.fill_between(x, x-overhead_error, x+overhead_error,  color='r', alpha=0.1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.xlim(0, np.max(jj.delta_obs) + eps)\n",
    "    plt.ylim(0, np.max(jj.expected_overhead) + eps/2)\n",
    "    \n",
    "    plt.xlabel(\"DeltaT between start of observations (minutes)\")\n",
    "    plt.ylabel(\"Expected overhead (exptime + slew) (minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99de7cd-c46e-4ddb-9cf5-344ac9d68546",
   "metadata": {},
   "source": [
    "## ConsDb Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610d121-b75a-456c-b642-23aa29dd0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add consdb\n",
    "\n",
    "day_obs_int = int(day_obs.replace('-', ''))\n",
    "\n",
    "visit_query = f'''\n",
    "    SELECT * FROM cdb_{instrument}.visit1\n",
    "     where day_obs = {day_obs_int}\n",
    "'''\n",
    "\n",
    "quicklook_query = f'''\n",
    "    SELECT q.*  FROM cdb_{instrument}.visit1_quicklook as q,\n",
    "    cdb_{instrument}.visit1 as v\n",
    "     WHERE v.day_obs = {day_obs_int} and q.visit_id = v.visit_id\n",
    "'''\n",
    "\n",
    "if have_consdb:\n",
    "    # Use the ConsDB Client, and add a couple of tries \n",
    "    consdb = ConsDbClient()\n",
    "    \n",
    "    try:\n",
    "        visits = consdb.query(visit_query).to_pandas()\n",
    "    except requests.HTTPError or requests.JSONDecodeError:\n",
    "        # Try twice\n",
    "        visits = consdb.query(visit_query).to_pandas()\n",
    "\n",
    "    quicklook = consdb.query(quicklook_query).to_pandas()\n",
    "\n",
    "else:\n",
    "    # Assumes at the USDF\n",
    "    connect = sqlalchemy.create_engine('postgresql://usdf@usdf-summitdb.slac.stanford.edu/exposurelog')\n",
    "    visits = pd.read_sql(visit_query, connection)\n",
    "    quicklook = pd.read_sql(quicklook_query, connection)\n",
    "\n",
    "if len(visits) > 0:\n",
    "    print(f\"Retrieved {len(visits)} visits from consdb\")\n",
    "    obj_vis = len(visits.query('img_type == \"OBJECT\"'))\n",
    "    print(f\"About {obj_vis} of these are object images\")\n",
    "\n",
    "if len(quicklook) > 0:\n",
    "    visits = visits.join(quicklook, on='visit_id', lsuffix='', rsuffix='_q')\n",
    "    print(f\"And added quicklook stats\")\n",
    "\n",
    "if len(visits) == 0:\n",
    "    print(f\"No visits for {telescope} on {day_obs} retrieved from consdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f668a-ec1b-4fc1-9b5a-4ca76845c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "short_cols = ['seq_num', 'obs_start_mjd', 'obs_end_mjd', 'exp_time', 'shut_time', 'dark_time', 's_ra', 's_dec', 'band', 'airmass', \n",
    "              'img_type', 'target_name', 'science_program', 'observation_reason', 'dimm_seeing']\n",
    "if len(visits)>0 and verbose:\n",
    "    display(visits[short_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286ec95-7e77-4deb-a7d3-036c3324da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a 'note' to match visits with the target/observation colors\n",
    "def construct_note(x):\n",
    "    if x.science_program == 'cwfs' or x.science_program == 'cwfs-focus-sweep':\n",
    "        note = 'cwfs'\n",
    "    elif x.science_program == \"BLOCK-295\":\n",
    "        note = 'calibrations'\n",
    "    elif x.target_name == 'FlatField position':\n",
    "        note = 'calibrations'\n",
    "    elif x.science_program == 'AUXTEL_PHOTO_IMAGING':\n",
    "        note = x.target_name.split('_')[0]\n",
    "    elif x.science_program == 'spec-survey':\n",
    "        note = x.target_name\n",
    "    else:\n",
    "        note = 'unknown'\n",
    "    return note\n",
    "\n",
    "if len(visits)>0:\n",
    "    note = visits.apply(construct_note, axis=1)\n",
    "    visits['note'] = note\n",
    "    print(\"ConsDB reconstructed note names: \", visits.note.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6d6a6-55b3-4936-9b03-170335ebea1a",
   "metadata": {},
   "source": [
    "## Timing of FBS Targets, Observations, and ConsDB Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89bf7e-ba97-4167-8f48-2999702d6323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mjd_to_datetime(mjd, timezone=tz):\n",
    "    return Time(mjd, format='mjd', scale='utc').to_datetime(timezone=timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9cdb65-a38c-49f3-a86c-68427d475110",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "ax_utc = ax.twiny()\n",
    "\n",
    "ax.set_title(f\"{telescope} DAYOBS {day_obs}\", pad=20)\n",
    "\n",
    "\n",
    "ax.fill_between([mjd_to_datetime(night_events['sun_n12_setting']), \n",
    "                  mjd_to_datetime(night_events['sun_n18_setting'])],\n",
    "                 2.5, 0.0, color='lightgray', alpha=0.3)\n",
    "ax.fill_between([mjd_to_datetime(night_events['sunset']), \n",
    "                 mjd_to_datetime(night_events['sun_n12_setting'])], \n",
    "                  2.5, 0.0, color='gray', alpha=0.3)\n",
    "ax.fill_between([mjd_to_datetime(night_events['sun_n18_rising']), \n",
    "                 mjd_to_datetime(night_events['sun_n12_rising'])],\n",
    "                 2.5, 0.0, color='lightgray', alpha=0.3)\n",
    "ax.fill_between([mjd_to_datetime(night_events['sun_n12_rising']), \n",
    "                 mjd_to_datetime(night_events['sunrise'])],\n",
    "                 2.5, 0.0, color='gray', alpha=0.3)\n",
    "\n",
    "ax.axvline(mjd_to_datetime(night_events['moonrise']), linestyle=':', color='blue', alpha=0.3)\n",
    "\n",
    "plot_fbs = True\n",
    "if len(jj) == 0:\n",
    "    plot_fbs = False\n",
    "plot_visits = True\n",
    "if len(visits) == 0:\n",
    "    plot_visits = False\n",
    "\n",
    "# Assign distinct target sets with different colors\n",
    "if len(jj) > 0:\n",
    "    notes = jj.note.unique()\n",
    "    note_colors = {}\n",
    "    for i, n in enumerate(notes):\n",
    "        note_colors[n] = cc.glasbey[i]\n",
    "elif len(visits) > 0:\n",
    "    notes = visits.note.unique()\n",
    "    note_colors = {}\n",
    "    for i, n in enumerate(notes):\n",
    "        note_colors[n] = cc.glasbey[i]\n",
    "else:\n",
    "    plot_fbs = False\n",
    "    plot_visits = False\n",
    "\n",
    "\n",
    "if plot_fbs:\n",
    "    # Plot the successfully recorded 'observation' scripts\n",
    "    for note in jj.note.unique():\n",
    "        j = jj.query('note == @note')\n",
    "        ax.plot(mjd_to_datetime(j.obs_obsmjd), j.airmass, '.', \n",
    "                 color=note_colors[note], label=f\"Target/Obs {note}\")\n",
    "    \n",
    "    if len(breaks) > 0:\n",
    "        for break_count, b in enumerate(breaks):\n",
    "            ax.fill_between(mjd_to_datetime(b), 2.5, 0.0, color='pink', alpha=0.3)\n",
    "            ax.text(mjd_to_datetime(b[0]), 0.97, break_count)\n",
    "\n",
    "    # Plot the observations that come after what looks like big overheads\n",
    "    #j = jj.iloc[overheads]\n",
    "    #plt.plot(j.obs_obsmjd, j.airmass, 'o', \n",
    "    #         markersize=10, color='k', markerfacecolor='none', label='Big Overheads')\n",
    "\n",
    "i = len(cc.glasbey) - 1\n",
    "if plot_visits:\n",
    "    # Plot the visits recorded in the consdb \n",
    "    for note in visits.note.unique():\n",
    "        try:\n",
    "            color = note_colors[note]\n",
    "        except KeyError:\n",
    "            color = cc.glasbey[i]\n",
    "            i -= 1\n",
    "        v = visits.query('note == @note')\n",
    "        ax.plot(mjd_to_datetime(v.obs_start_mjd), v.airmass, '.', \n",
    "                 markersize=9, markerfacecolor='none', alpha=0.6,\n",
    "                 label=f'Visits {note}', color=color, zorder=3)\n",
    "\n",
    "if plot_fbs:\n",
    "    # Plot the targets which did not get 'observations' recorded\n",
    "    for note in targets.note.unique():\n",
    "        try:\n",
    "            color = note_colors[note]\n",
    "        except KeyError:\n",
    "            color = cc.glasbey[i]\n",
    "            i -= 1\n",
    "        t = targets.query('note == @note and obs_id == -1')\n",
    "        ax.plot(mjd_to_datetime(t.target_obsmjd), \n",
    "                 t.airmass, '+', markersize=9, \n",
    "                 label=f'Failed {note}', color=color, zorder=1)\n",
    "\n",
    "if len(visits) > 0 | len(targets) > 0:\n",
    "    ax.legend(loc=(1.01, 0.0))\n",
    "\n",
    "x0 = night_events['sunset']+30/60/24\n",
    "\n",
    "ax.set_xlim(mjd_to_datetime(night_events['sunset']+30/60/24), \n",
    "         mjd_to_datetime(night_events['sunrise']-30/60/24))\n",
    "ax_utc.set_xlim(mjd_to_datetime(night_events['sunset']+30/60/24, timezone=tz_utc), \n",
    "         mjd_to_datetime(night_events['sunrise']-30/60/24, timezone=tz_utc))\n",
    "\n",
    "# Set ticks relevant sides\n",
    "ax.tick_params(axis=\"x\", bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "ax_utc.tick_params(axis=\"x\", bottom=False, top=True, labelbottom=False, labeltop=True)\n",
    "\n",
    "# Rotate and align bottom ticklabels\n",
    "plt.setp([tick.label1 for tick in ax.xaxis.get_major_ticks()], rotation=45,\n",
    "         ha=\"right\", va=\"center\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Rotate and align top ticklabels\n",
    "plt.setp([tick.label2 for tick in ax_utc.xaxis.get_major_ticks()], rotation=45,\n",
    "         ha=\"left\", va=\"center\",rotation_mode=\"anchor\")\n",
    "\n",
    "plt.grid(True, alpha=0.2)\n",
    "\n",
    "plt.ylim(2.3, 0.9)\n",
    "\n",
    "ax.set_xlabel(f\"Time ({tz})\", fontsize=\"large\")\n",
    "ax_utc.set_xlabel(\"Time (UTC)\", fontsize='large')\n",
    "_ = plt.ylabel(\"Airmass\", fontsize=\"large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d74e47-5c6a-48a3-8dcd-d0073041dc2e",
   "metadata": {},
   "source": [
    "## EFD Error messages and scripts run during \"breaks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27120f-ab2b-4e2a-ae54-d11015fdab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = await efd_client.get_topics()\n",
    "if telescope.lower().startswith('aux'):\n",
    "    err_topics = [t for t in topics if 'err' in t and 'MT' not in t]\n",
    "else:\n",
    "    err_topics = [t for t in topics if 'err' in t and 'AT' not in t]\n",
    "\n",
    "try: \n",
    "    breaks\n",
    "except NameError:\n",
    "    breaks = [[sunset, sunrise]]\n",
    "\n",
    "for i, b in enumerate(breaks):\n",
    "    t1 = Time(b[0], format='mjd', scale='utc')\n",
    "    t2 = Time(b[1], format='mjd', scale='utc')\n",
    "    print(f\"During break {i} ({round((t2-t1).sec/60)} minutes)- {mjd_to_datetime(t1.mjd)} to {mjd_to_datetime(t2.mjd)} : \")\n",
    "    # Poll error topics\n",
    "    for topic in err_topics:\n",
    "        df = await efd_client.select_time_series(topic, ['errorCode', 'errorReport'], t1, t2)\n",
    "        if len(df) > 0:\n",
    "            print(' ', topic)\n",
    "            for ij, row in df.iterrows():\n",
    "                print(f\"   {mjd_to_datetime(Time(ij).mjd)} {row.errorReport}\")\n",
    "    # Also check what was going on in scriptqueue\n",
    "    df = await efd_client.select_time_series('lsst.sal.ScriptQueue.logevent_script', ['path'], t1, t2, index=salindex)\n",
    "    if len(df) > 0:\n",
    "        print(f'  Scripts: {df.path.unique()}') \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c82ae-1039-41dd-b3bd-9f48aa39184f",
   "metadata": {},
   "source": [
    "## Narrative Log content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03708105-c784-48c7-ac28-8ba4fbc90a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab information from the narrative log -- \n",
    "# How to tell what is auxtel and what is simonyi or other system? do we care or is this for the reader? \n",
    "connection = sqlalchemy.create_engine('postgresql://usdf@usdf-summitdb.slac.stanford.edu/narrativelog')\n",
    "\n",
    "narrative_query = f\"select site_id, message_text, time_lost, date_begin, date_invalidated, systems, \\\n",
    "    subsystems, cscs, date_end, time_lost_type from message where date_begin between '{sunset.iso}' and '{sunrise.iso}'\"\n",
    "\n",
    "narrative_log = pd.read_sql(narrative_query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca2a5e-7f72-4f8c-b993-efdb326cbf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Host usdf-summitdb.slac.stanford.edu, database narrativelog, schema public, table message\n",
    "# Host usdf-summitdb.slac.stanford.edu, database exposurelog, schema public, table message (consdb is in exposurelog too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076d076-9f43-4f8a-81e8-e5b79b3a2b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#narrative_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853481c0-8c98-4a99-98cd-aa692da6445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in narrative_log.iterrows():\n",
    "    t_start = Time(row[\"date_begin\"])\n",
    "    t_end = Time(row[\"date_end\"])\n",
    "    log_time =f\"Log message at: {t_start} -- {t_end}\" # ({t_start.mjd} {t_end.mjd})\"\n",
    "    display(Markdown(f\"<strong>{log_time}</strong>\"))\n",
    "    print('time lost', row['time_lost'], 'time lost type', row['time_lost_type'], 'systems', row['systems'], 'subsystems', row['subsystems'], 'CSCS', row['cscs'])\n",
    "    print(row[\"message_text\"].replace(\"\\r\\n\\r\\n\", \"\"))\n",
    "    if row['date_invalidated'] is not None:\n",
    "        print(f\"Date invalidated {row['date_invalidated']}\")\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
