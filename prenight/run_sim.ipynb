{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be ignored in Times Square\n",
    "import rubin_nights.dayobs_utils as rn_dayobs\n",
    "\n",
    "day_obs = rn_dayobs.day_obs_str_to_int(rn_dayobs.today_day_obs())\n",
    "sim_nights = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d4bff-443a-4cb9-9342-09f059bed6df",
   "metadata": {},
   "source": [
    "# Run simulation for {params.day_obs} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc583dd5-34fe-4838-a640-2f5b07c5275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getenv(\"EXTERNAL_INSTANCE_URL\") is not None:\n",
    "    print(\"updating lsst_survey_sim and ts_fbs_utils\")\n",
    "    !pip install --user --upgrade git+https://github.com/lsst-sims/lsst_survey_sim.git  --no-deps --no-build-isolation  > /dev/null 2>&1\n",
    "    !pip install --user --upgrade git+https://github.com/lsst-ts/ts_fbs_utils.git  --no-deps --no-build-isolation > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a9f35-ede0-4cea-860a-db5b196d3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubin_scheduler\n",
    "import lsst.ts.fbs.utils\n",
    "import lsst_survey_sim\n",
    "print(\"rubin_scheduler\", rubin_scheduler.__version__)\n",
    "print(\"ts_fbs_utils\", lsst.ts.fbs.utils.__version__)\n",
    "print(\"lsst_survey_sim\", lsst_survey_sim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some configuration content\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Who is running the notebook? Some of us have preferences ..\n",
    "username = getpass.getuser()\n",
    "# Where is the notebook running? (RSPs are 'special')\n",
    "current_location = os.getenv(\"EXTERNAL_INSTANCE_URL\", \"\")\n",
    "\n",
    "# RUBIN_SIM_DATA_DIR at usdf\n",
    "if 'usdf' in current_location:\n",
    "    os.environ[\"RUBIN_SIM_DATA_DIR\"] = \"/sdf/data/rubin/shared/rubin_sim_data\"\n",
    "\n",
    "# TOKEN CONFIGURATION\n",
    "if current_location != \"\":\n",
    "    # You are on an rsp.\n",
    "    # You should use the default RSP values, whether summit/base/USDF.\n",
    "    tokenfile = None\n",
    "    site = None\n",
    "# If you are outside of an RSP? - just use USDF and your own USDF-RSP token\n",
    "# See https://rsp.lsst.io/guides/auth/creating-user-tokens.html\n",
    "else:\n",
    "    # Substitute the location of your own tokenfile\n",
    "    tokenfile = os.getenv(\"ACCESS_TOKEN_FILE\", \"\")\n",
    "    site = os.getenv(\"DATA_SITE\", \"\")\n",
    "    if tokenfile == \"\":\n",
    "        # A very reasonable backup.\n",
    "        tokenfile = os.path.join(os.path.expanduser(\"~\"), \".lsst/usdf_rsp\")\n",
    "        site = 'usdf'\n",
    "\n",
    "# NOTE: THIS IS A USEFUL TECHNIQUE FOR ANYONE TO USE BRANCHES\n",
    "# PATH MODIFICATIONS FOR ERIC\n",
    "if username=='neilsen' and current_location==\"https://usdf-rsp.slac.stanford.edu\":\n",
    "    # Modifications of the python path with\n",
    "    # sys.path do not work if the same namespace\n",
    "    # is already scanned in the PYTHONPATH.\n",
    "    # Get rid of the modules pre-loaded so the\n",
    "    # interpreter reloads lsst.blah.blah.blah\n",
    "    # after we have made our modifications\n",
    "    # to sys.path.\n",
    "    sys.modules.pop(\"lsst.ts\", None)\n",
    "    sys.modules.pop(\"lsst\", None)\n",
    "    # - add ts_fbs_utils and lsst_survey_sim to the path\n",
    "    sys.path.insert(0, \"/sdf/data/rubin/user/neilsen/devel/lsst_survey_sim\")\n",
    "    sys.path.insert(0, \"/sdf/data/rubin/user/neilsen/devel/ts_fbs_utils/python\")\n",
    "\n",
    "\n",
    "\n",
    "# CONFIGURE PATHS for ts_config_scheduler_root\n",
    "ts_config_scheduler_root = None\n",
    "\n",
    "if username=='neilsen' and current_location==\"https://usdf-rsp.slac.stanford.edu\":\n",
    "    ts_config_scheduler_root = \"/sdf/data/rubin/user/neilsen/devel/ts_config_scheduler\"\n",
    "    do_git_stuff = False\n",
    "\n",
    "elif username=='lynnej' and current_location == \"\":\n",
    "    ts_config_scheduler_root = \"/Users/lynnej/lsst_repos/ts_config_scheduler\"\n",
    "    do_git_stuff = True\n",
    "\n",
    "# For everyone who did not set ts_config_scheduler_root path\n",
    "if ts_config_scheduler_root is None:\n",
    "    # Just make a new clone for ts_config_scheduler in a temporary directory\n",
    "    import tempfile\n",
    "    ts_config_scheduler_root = tempfile.mkdtemp()\n",
    "    ts_config_is_temp = True\n",
    "    do_git_stuff = True\n",
    "else:\n",
    "    ts_config_is_temp = False\n",
    "\n",
    "assert isinstance(ts_config_scheduler_root, str), \"Please set ts_config_scheduler_root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the remaining \n",
    "import warnings\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"lsst_survey_sim\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"rubin_nights\").setLevel(logging.INFO)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import colorcet as cc\n",
    "import skyproj\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import datetime\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "from rubin_scheduler.site_models import Almanac\n",
    "from rubin_scheduler.scheduler import sim_runner\n",
    "from rubin_scheduler.scheduler.schedulers import CoreScheduler\n",
    "from rubin_scheduler.scheduler.features import Conditions\n",
    "from rubin_scheduler.scheduler.utils import TargetoO, SimTargetooServer, SchemaConverter\n",
    "from rubin_scheduler.utils import ddf_locations, angular_separation, approx_ra_dec2_alt_az, Site, SURVEY_START_MJD\n",
    "\n",
    "import rubin_sim.maf as maf\n",
    "from rubin_sim.data import get_baseline\n",
    "\n",
    "from rubin_nights import connections\n",
    "import rubin_nights.lfa_data as rn_lfa\n",
    "import rubin_nights.dayobs_utils as rn_dayobs\n",
    "import rubin_nights.plot_utils as rn_plots\n",
    "import rubin_nights.augment_visits as augment_visits\n",
    "import rubin_nights.rubin_scheduler_addons as rn_sch\n",
    "import rubin_nights.rubin_sim_addons as rn_sim\n",
    "import rubin_nights.observatory_status as observatory_status\n",
    "import rubin_nights.scriptqueue as scriptqueue\n",
    "import rubin_nights.scriptqueue_formatting as scriptqueue_formatting\n",
    "\n",
    "from lsst_survey_sim import lsst_support, simulate_lsst, plot\n",
    "\n",
    "# Will swap to use lsst_utils .. \n",
    "band_colors = rn_plots.PlotStyles.band_colors\n",
    "\n",
    "#%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default is to run this notebook for one day (today). \n",
    "# In this case, you generally want no downtime or clouds - just all the possible visits for tonight all night.\n",
    "# However -- you COULD run in the past, \n",
    "# in which case you might want to run at the times the FBS was on-sky (real_downtime=True).\n",
    "# You could also run for more than one night, \n",
    "# in which case  you might want to run with downtime and clouds (add_downtime=True, add_clouds=True).\n",
    "# This cell evaluates if you are running for tonight, or in the past and sets the flags according to the logic above.\n",
    "\n",
    "# today_dayobs is the day of today - if it is larger than day_obs, then we are running in the past.\n",
    "today_dayobs = rn_dayobs.day_obs_str_to_int(rn_dayobs.today_day_obs())\n",
    "\n",
    "# Knowing the day after day_obs will be useful: \n",
    "day_obs_time = rn_dayobs.day_obs_to_time(day_obs)\n",
    "next_day_obs_time = rn_dayobs.day_obs_to_time(day_obs) + TimeDelta(1, format='jd')\n",
    "next_day_obs = rn_dayobs.day_obs_str_to_int(rn_dayobs.time_to_day_obs(next_day_obs_time))\n",
    "\n",
    "# Some parameters relating to downtime setup for model observatory\n",
    "day_downtime = day_obs\n",
    "if sim_nights == 1:\n",
    "    # Single night, probably no downtime or clouds.\n",
    "    add_downtime = False\n",
    "    real_downtime = False\n",
    "    add_clouds = False\n",
    "else:\n",
    "    # Multiple nights, probably want downtime and clouds.\n",
    "    add_downtime = True\n",
    "    real_downtime = True\n",
    "    add_clouds = True\n",
    "# But -- beyond those, if we are running in the PAST, \n",
    "# we will want to use the real on-sky time for the FBS visits.\n",
    "# This means adding downtime, using the real-downtime, but not adding clouds.\n",
    "# We will also need to be careful about what data we query for and what we add to the FBS.\n",
    "if day_obs < today_dayobs:    \n",
    "    print(\"Checking the past, will restrict uptime to time acquiring science visits\")\n",
    "    add_downtime = True\n",
    "    real_downtime = True\n",
    "    add_clouds = False\n",
    "    day_downtime = next_day_obs\n",
    "\n",
    "print(\"Setting up to with downtimes like:\")\n",
    "print(\"add_downtime =\", add_downtime)\n",
    "print(\"real_downtime = \", real_downtime)\n",
    "print(\"add_clouds = \", add_clouds)\n",
    "\n",
    "# Used for various things inside the FBS including footprints and DDF start\n",
    "survey_start = SURVEY_START_MJD  \n",
    "\n",
    "# Programs to consider FBS on-sky time\n",
    "programs = [\"BLOCK-407\", \"BLOCK-408\"]\n",
    "print(\"Potential science programs : \", programs)\n",
    "\n",
    "sunset, sunrise = rn_dayobs.day_obs_sunset_sunrise(day_obs, sun_alt=-12)\n",
    "print(f\"Simulation for {sim_nights} nights starting on :\")\n",
    "print(f\"DayObs {day_obs}, -12 deg sunset {sunset.iso}, -12 deg sunrise {sunrise.iso}\")\n",
    "\n",
    "sunset18, sunrise18 = rn_dayobs.day_obs_sunset_sunrise(day_obs, sun_alt=-18)\n",
    "print(f\"DayObs {day_obs}, -18 deg sunset {sunset18.iso}, -18 deg sunrise {sunrise18.iso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = connections.get_clients(tokenfile=tokenfile, site=site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some configuration information ... I'm not sure whether we can/will use this at present.\n",
    "\n",
    "# run branch\n",
    "q = endpoints['obsenv'].select_top_n(\"lsst.obsenv.run_branch\", ['branch_name'], 1, time_cut=sunset)\n",
    "q2 = endpoints['obsenv'].select_time_series(\"lsst.obsenv.run_branch\", [\"branch_name\"], sunset, sunrise)\n",
    "runbranch = pd.concat([q, q2])\n",
    "display(runbranch)\n",
    "current_runbranch = runbranch.branch_name.iloc[-1]\n",
    "print(f\"Current run branch {current_runbranch}\")\n",
    "# configuration information\n",
    "q = endpoints['efd'].select_top_n('lsst.sal.Scheduler.logevent_configurationApplied', [\"configurations\", \"salIndex\", \"private_origin\", \"url\", \"version\"], 1, time_cut=sunset, index=1)\n",
    "q2 = endpoints['efd'].select_time_series('lsst.sal.Scheduler.logevent_configurationApplied', [\"configurations\", \"salIndex\", \"private_origin\", \"url\", \"version\"], sunset, sunrise, index=1)\n",
    "q = pd.concat([q, q2])\n",
    "def strip_repo(x: pd.Series):\n",
    "    return x.url.split(\"/\")[-3]\n",
    "def strip_version(x: pd.Series):\n",
    "    return x.version.replace(\"heads/\", \"\")\n",
    "def strip_yaml(x: pd.Series):\n",
    "    return x.configurations.split(\",\")[-1]\n",
    "config_repo = q.apply(strip_repo, axis=1)\n",
    "config_version = q.apply(strip_version, axis=1)\n",
    "config_yaml = q.apply(strip_yaml, axis=1)\n",
    "configs = pd.DataFrame([config_repo, config_version, config_yaml], columns=q.index, index=['config_repo', 'config_commit', 'config_yaml']).T\n",
    "current_commit = config_version.iloc[0]\n",
    "display(configs)\n",
    "print(f\"Current commit {current_commit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will let you update your version of `ts_config_scheduler` to the commit from the configuration above. (not clear if desirable).\n",
    "# But it would also just let you clone `ts_config_scheduler` if you didn't have it already. (useful for times square). \n",
    "# If `do_git_stuff` is False, none of these git updates will happen anyway. \n",
    "\n",
    "if do_git_stuff:\n",
    "    # Git checkout ts_config_scheduler and set the configs to use.\n",
    "    ts_commit = 'develop'\n",
    "    #ts_commit = current_commit\n",
    "    simulate_lsst.get_configuration(ts_commit, clone_path=ts_config_scheduler_root)\n",
    "\n",
    "# Now set the (hard-coded) paths from `ts_config_scheduler` to the actual survey configurations.\n",
    "config_script_path = os.path.join(ts_config_scheduler_root, \"Scheduler/feature_scheduler/maintel/\", \"fbs_config_lsst_survey.py\")\n",
    "config_ddf_script_path = os.path.join(ts_config_scheduler_root, \"Scheduler/ddf_gen/lsst_ddf_gen_block_407.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve previous visits to start scheduler.\n",
    "# Note that we will try to retrieve visits up to day_obs + 1 day. \n",
    "# This will allow using the actual on-sky time even for day_obs.\n",
    "\n",
    "refresh_visits = True\n",
    "\n",
    "if refresh_visits:\n",
    "    initial_opsim = simulate_lsst.fetch_previous_visits(next_day_obs, tokenfile=tokenfile, site=site)\n",
    "    if initial_opsim is not None:\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.simplefilter(\"always\") \n",
    "            initial_opsim.to_hdf(\"opsim.h5\", key='visits')\n",
    "else:\n",
    "    initial_opsim = pd.read_hdf(\"opsim.h5\")\n",
    "    \n",
    "if initial_opsim is None:\n",
    "    print(\"No visits found\")\n",
    "    print(\"If this was unexpected -- this is probably a good time to abort this sim.\")\n",
    "else:\n",
    "    print(f\"Found {len(initial_opsim)} visits\")\n",
    "    print(f\"max day_obs in visits {initial_opsim.day_obs.max()}\")\n",
    "    print(f\"will be running simulation for dayobs {day_obs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve ToO events. \n",
    "# Because ToO events are only available at either summit or base (with different information in each!)\n",
    "# this will not work from the USDF. The `test_too.p` is a pickle of the ToO information from the \n",
    "# too running 20251114 - 20251121 and will let the FBS set up accordingly.\n",
    "\n",
    "import pickle\n",
    "try_toos = False\n",
    "if try_toos:\n",
    "    lookback = TimeDelta(1, format='jd')\n",
    "    toos = simulate_lsst.fetch_too_events(sunset - lookback, sunrise, site='summit')\n",
    "    if toos is not None:\n",
    "        with open('test_too.p', 'wb') as f:\n",
    "            pickle.dump(toos, f)\n",
    "else:\n",
    "    try:\n",
    "        with open('test_too.p', 'rb') as f:\n",
    "            toos = pickle.load(f)\n",
    "            # modify -- the pickle has this set to 1 and that is bad.\n",
    "            toos[0].duration = 10.0\n",
    "    except FileNotFoundError:\n",
    "        toos = None\n",
    "\n",
    "print(f\"Retrieved {len(toos)} ToOs\")\n",
    "# Wrap up ToOs for sim target server - only last currently relevant\n",
    "too_server = SimTargetooServer(toos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the band scheduler.\n",
    "band_scheduler = simulate_lsst.setup_band_scheduler()\n",
    "\n",
    "# Check what bands it expects for day_obs? \n",
    "conditions = Conditions(mjd=sunset.mjd)\n",
    "print(f\"Bands expected to be available {day_obs}\", band_scheduler(conditions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure scheduler.\n",
    "\n",
    "# Sometimes we might want or need to start from a snapshot (warm start) rather than the configuration (cold start).\n",
    "start_from_snapshot = False\n",
    "if start_from_snapshot:\n",
    "    # Try last snapshot before start of this dayobs \n",
    "    t_max_snapshot = day_obs_time\n",
    "    topic = \"lsst.sal.Scheduler.logevent_largeFileObjectAvailable\"\n",
    "    snapshots = endpoints['efd'].select_top_n(topic, ['url'], num=1, time_cut=t_max_snapshot, index=1)\n",
    "    uri = snapshots['url'].iloc[-1]\n",
    "    print(f\"Fetching snapshot {uri}\")\n",
    "    starting_scheduler, summit_conditions = rn_lfa.get_scheduler_snapshot(uri, at_usdf=True)\n",
    "    # Just check that these are the right kind of things \n",
    "    assert isinstance(starting_scheduler, CoreScheduler)\n",
    "    assert isinstance(summit_conditions, Conditions)\n",
    "    nside = starting_scheduler.nside\n",
    "    # have to do some footwork to update snapshot to where we expect to resume observations \n",
    "    # we actually probably have to do this with target_visits ...\n",
    "    # let's just use the last snapshot for now (we know this was the end of the ToO)\n",
    "\n",
    "else:\n",
    "    # Configure scheduler, pass it ToOs to set up ToOSurveys, and add previous observations.\n",
    "    if initial_opsim is not None:\n",
    "        initial_opsim_scheduler_startup = initial_opsim.query(\"day_obs < @day_obs\")\n",
    "    else:\n",
    "        initial_opsim_scheduler_startup = None\n",
    "        print(\"Just checking - you wanted to run the sim with no previous visits information?\")\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning) \n",
    "        starting_scheduler, _, nside = simulate_lsst.setup_scheduler(config_script_path=config_script_path, \n",
    "                                                                     config_ddf_script_path=config_ddf_script_path,\n",
    "                                                                     day_obs=day_obs, \n",
    "                                                                     band_scheduler=band_scheduler,\n",
    "                                                                     too_server=too_server,\n",
    "                                                                     initial_opsim=initial_opsim_scheduler_startup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcfd35-8f81-4ca5-9b9d-6feaec1ed583",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ts_config_is_temp:\n",
    "    import shutil\n",
    "    shutil.rmtree(ts_config_scheduler_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now set up the ModelObservatory, including the ToO server and building downtime. \n",
    "\n",
    "# To note about the current downtime model:\n",
    "# Even if add_downtime is False, the end of the night (-18deg twi+) will be blocked as downtime to match observing requirements\n",
    "# And also the start of the night (-18deg twi-) will be blocked off based on experience getting on sky .. this is improving though! \n",
    "# If add_downtime is True:\n",
    "# The first 100 days from \"day_downtime\" onward are assigned with a LOT of downtime. Perhaps coming close to our on-sky performance.\n",
    "# This is based on the downtime model that only exists in lsst_survey_sim.lsst_support.survey_times\n",
    "# The remainder of the downtime is assigned based on rubin_scheduler.site_models.UnscheduledDowntimeMoreY1Data and decreases through Y1\n",
    "# Further: if \"real_downtime\" is True, then the actual on-sky FBS time is used to determine the downtime prior to day_downtime. \n",
    "\n",
    "# This is a way to manually swap the seeing.\n",
    "swap_seeing = False\n",
    "if swap_seeing:\n",
    "    # The fill value for missing DIMM values is 1\n",
    "    seeing=1.0\n",
    "else:\n",
    "    seeing=None\n",
    "\n",
    "    \n",
    "starting_observatory, survey_info = simulate_lsst.setup_observatory(day_obs=day_downtime, \n",
    "                                                                    nside=nside, \n",
    "                                                                    add_downtime=add_downtime, \n",
    "                                                                    add_clouds=add_clouds, \n",
    "                                                                    seeing=seeing, \n",
    "                                                                    real_downtime=real_downtime,\n",
    "                                                                    initial_opsim=initial_opsim, \n",
    "                                                                    too_server=too_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Look at time-onsky / availability during the period day_obs to day_obs + mask_days \n",
    "# # Not necessary but a useful insight into current fraction of downtime to compare with real on-sky time\n",
    "# mask_days = 30\n",
    "# print(f\"Modeled availability over next {mask_days} nights\")\n",
    "# mask = np.where(survey_info['dayobsmjd'] < rn_dayobs.day_obs_to_time(day_obs).mjd + mask_days)\n",
    "# print(f\"Total nighttime {survey_info[\"hours_in_night\"][mask].sum()}, \")\n",
    "# print(f\"total downtime {survey_info[\"downtime_per_night\"][mask].sum()}, \")\n",
    "# print(f\"available time {survey_info[\"hours_in_night\"][mask].sum() - survey_info[\"downtime_per_night\"][mask].sum()}\")\n",
    "# print(f\"Average availability over {mask_days} days {(survey_info[\"hours_in_night\"][mask].sum() - survey_info[\"downtime_per_night\"][mask].sum()) / survey_info[\"hours_in_night\"][mask].sum()}\")\n",
    "# print(f\"Average availability over survey {survey_info['system_availability']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of the current downtime (black = downtime; orange = -12 deg sunrise, blue = -12 deg sunset\n",
    "print(\"Illustrate survey downtime assumptions\")\n",
    "for start, end in survey_info['downtimes']:\n",
    "    x = np.floor(start - 0.5)\n",
    "    plt.plot((x, x), (start - x, end - x) , color='k') \n",
    "x = np.floor(survey_info['sunsets12'] - 0.5)\n",
    "y = survey_info['sunsets12'] - x\n",
    "plt.fill_between(x, 0.8, y)\n",
    "x = np.floor(survey_info['sunrises12'] - 0.5)\n",
    "y = survey_info['sunrises12'] - x\n",
    "plt.axvline(rn_dayobs.day_obs_to_time(day_obs).mjd, color='r', linestyle=':', linewidth=1.8)\n",
    "plt.fill_between(x, y, 1.6)\n",
    "plt.ylim(0.9, 1.5)\n",
    "plt.xlim(survey_info['survey_start'].mjd, rn_dayobs.day_obs_to_time(day_obs).mjd + 200)\n",
    "plt.xlabel(\"MJD\", fontsize='large')\n",
    "_ = plt.ylabel(\"Fraction of MJD\", fontsize='large')\n",
    "#plt.savefig(\"onsky_downtime.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be useful to understsand which DDFs we might or might not be observing, when, and why. \n",
    "# Not required for running simulation. \n",
    "print(f\"Visualize DDF accessibility on {day_obs}\")\n",
    "check_ddfs = True\n",
    "if check_ddfs:\n",
    "    ddfs = ddf_locations(skycoords=True)\n",
    "    lsst_site = Site('LSST')\n",
    "    times = np.arange(sunset.mjd - 0.1, sunrise.mjd + 0.1, 0.05/24)\n",
    "    sunmoon = survey_info['almanac'].get_sun_moon_positions(times)\n",
    "    moon_ra = sunmoon['moon_RA']\n",
    "    moon_dec = sunmoon['moon_dec']\n",
    "    sun_alt = np.degrees(sunmoon['sun_alt'])\n",
    "    ddf_moon_dist = {}\n",
    "    ddf_alt = {}\n",
    "    for ddf in ddfs:\n",
    "        ddf_moon_dist[ddf] = angular_separation(ddfs[ddf].ra.deg, ddfs[ddf].dec.deg, np.degrees(moon_ra), np.degrees(moon_dec))\n",
    "        alt, az = approx_ra_dec2_alt_az(ddfs[ddf].ra.deg, ddfs[ddf].dec.deg, lsst_site.latitude, lsst_site.longitude, times, lmst=None)\n",
    "        ddf_alt[ddf] = alt\n",
    "    \n",
    "    plt.figure()\n",
    "    for ddf in ddfs:\n",
    "        mask = np.where((sun_alt <= -12) & (ddf_alt[ddf] > 40))\n",
    "        plt.plot(Time(times[mask], format='mjd').to_datetime(), ddf_moon_dist[ddf][mask], marker='.', linestyle='', label=ddf)\n",
    "    plt.legend(loc=(1.01, 0.5))\n",
    "    plt.axvline(sunset.to_datetime(), color='k', linestyle=':')\n",
    "    plt.axvline(sunrise.to_datetime(), color='k', linestyle=':')\n",
    "    plt.axhline(30)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"MJD\")\n",
    "    plt.ylabel(\"Distance to moon (deg)\")\n",
    "    \n",
    "    plt.figure()\n",
    "    for ddf in ddfs:\n",
    "        mask = np.where((sun_alt <= -12) & (ddf_alt[ddf] > 40))\n",
    "        plt.plot(Time(times[mask], format='mjd').to_datetime(), ddf_alt[ddf][mask], marker='.', linestyle='', label=ddf)\n",
    "    plt.legend(loc=(1.01, 0.5))\n",
    "    plt.axvline(sunset.to_datetime(), color='k', linestyle=':')\n",
    "    plt.axvline(sunrise.to_datetime(), color='k', linestyle=':')\n",
    "    plt.axhline(30)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"MJD\")\n",
    "    plt.ylabel(\"Altitude (deg)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a copy of the model observatory and scheduler below. \n",
    "# Rerun this cell if you wish to rerun simulations below. \n",
    "\n",
    "observatory = copy.deepcopy(starting_observatory)\n",
    "scheduler = copy.deepcopy(starting_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation for some nights, from day_obs to day_obs + sim_nights.\n",
    "print(\"==================\")\n",
    "print(\"Running simulation\")\n",
    "print(\"==================\")\n",
    "observations, scheduler, observatory, rewards, obs_rewards, survey_info = simulate_lsst.run_sim(scheduler=scheduler, \n",
    "                                                                                                    band_scheduler=band_scheduler,\n",
    "                                                                                                    observatory=observatory,\n",
    "                                                                                                    survey_info=survey_info,\n",
    "                                                                                                    day_obs=day_obs,\n",
    "                                                                                                    sim_nights=sim_nights, \n",
    "                                                                                                    keep_rewards=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce6687-682d-4a70-817a-626d9ea0add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = np.where(q.band.values[1:] != q.band.values[:-1])[0]\n",
    "# counter = 0\n",
    "# altchange = []\n",
    "# for i in idx:\n",
    "#     alts = np.degrees(q.iloc[i:i+5]['alt'])\n",
    "#     altrange = alts.max() - alts.min()\n",
    "#     altchange.append(altrange)\n",
    "#     if altrange > 5:\n",
    "#         print(i, alts.max(), alts.min(), alts.max() - alts.min(), np.unique(q.iloc[i:i+5]['observation_reason']))\n",
    "#         counter += 1\n",
    "# print(counter)\n",
    "\n",
    "# _ = plt.hist(altchange, bins=20)\n",
    "# plt.xlabel(\"alt max - alt min within 5 visits of filter change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Available if you need to run ata specific timespan within the night (should we start 10 minutes later, for better ToO coverage, for example).\n",
    "\n",
    "# # sunset, sunrise = rn_dayobs.day_obs_sunset_sunrise(day_obs, sun_alt=-12)\n",
    "# # start = sunset.mjd - 0.1/24\n",
    "# start = (sunset + TimeDelta(20/60/24, format='jd')).mjd\n",
    "# end = sunrise.mjd\n",
    "# end = start + 4/24\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "#     vals = sim_runner(\n",
    "#         observatory,\n",
    "#         scheduler,\n",
    "#         band_scheduler=band_scheduler,\n",
    "#         sim_start_mjd=start,\n",
    "#         sim_duration=end-start, \n",
    "#         record_rewards=False,\n",
    "#         verbose=True,\n",
    "#     )\n",
    "# observatory = vals[0]\n",
    "# scheduler = vals[1]\n",
    "# observations = vals[2]\n",
    "# if len(vals) == 5:\n",
    "#     rewards = vals[3]\n",
    "#     obs_rewards = vals[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all visits have metadata.\n",
    "# Any empty string values here indicates a problem.\n",
    "# But it can also just be useful to see what programs/regions were observed.\n",
    "obs = pd.DataFrame(observations)\n",
    "\n",
    "def split_regions(x):\n",
    "    regions = set()\n",
    "    for k in x: #.target_name:\n",
    "        regions = regions.union(set([kk.replace(' ', '') for kk in k.split(',')]))\n",
    "    regions = list(regions)\n",
    "    regions.sort()\n",
    "    return regions\n",
    "print(\"Regions observed\", split_regions(obs.target_name.unique()))\n",
    "print(\"Science programs\", obs.science_program.unique())\n",
    "print(\"Observation Reasons / Surveys\", np.sort(obs.observation_reason.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we only have simulated a few nights, make a plot of the requested observations (open circles, == 'targets').\n",
    "# If this is in the past (or on a night in progress), will also include the actual visits (dots). \n",
    "if sim_nights < 3:\n",
    "\n",
    "    targets = pd.DataFrame(observations)\n",
    "    \n",
    "    from zoneinfo import ZoneInfo\n",
    "    tz = ZoneInfo(\"Chile/Continental\")\n",
    "    tz_utc = ZoneInfo(\"UTC\")\n",
    "    telescope = \"Simonyi\"\n",
    "\n",
    "    lsst_site = Site('LSST')\n",
    "    almanac = Almanac()\n",
    "    night_events = almanac.get_sunset_info(evening_date=rn_dayobs.day_obs_int_to_str(day_obs), longitude=lsst_site.longitude_rad)\n",
    "\n",
    "    def mjd_to_datetime(mjd, scale='utc', timezone=tz):\n",
    "        return Time(mjd, format='mjd', scale=scale).utc.to_datetime(timezone=timezone)\n",
    "        \n",
    "    eps = 1\n",
    "    fig, ax = plt.subplots(figsize=(13, 8))\n",
    "    ax_utc = ax.twiny()\n",
    "    \n",
    "    ax.set_title(f\"{telescope} DAYOBS {day_obs}\", pad=20)\n",
    "    \n",
    "    # Shade astronomical events\n",
    "    ax.fill_between([mjd_to_datetime(night_events['sun_n12_setting']), \n",
    "                      mjd_to_datetime(night_events['sun_n18_setting'])],\n",
    "                     2.5, 0.0, color='lightgray', alpha=0.3)\n",
    "    ax.fill_between([mjd_to_datetime(night_events['sunset']), \n",
    "                     mjd_to_datetime(night_events['sun_n12_setting'])], \n",
    "                      2.5, 0.0, color='gray', alpha=0.3)\n",
    "    ax.fill_between([mjd_to_datetime(night_events['sun_n18_rising']), \n",
    "                     mjd_to_datetime(night_events['sun_n12_rising'])],\n",
    "                     2.5, 0.0, color='lightgray', alpha=0.3)\n",
    "    ax.fill_between([mjd_to_datetime(night_events['sun_n12_rising']), \n",
    "                     mjd_to_datetime(night_events['sunrise'])],\n",
    "                     2.5, 0.0, color='gray', alpha=0.3)\n",
    "    # Azimuth constraint period\n",
    "    ax.fill_between([mjd_to_datetime(night_events['sunrise'] - 3/24),\n",
    "                    mjd_to_datetime(night_events['sun_n18_rising'])],\n",
    "                    2.5, 0.0, color='pink', alpha=0.1)\n",
    "    \n",
    "    if not np.isnan(night_events['moonrise']):\n",
    "        ax.axvline(mjd_to_datetime(night_events['moonrise']), linestyle='-', color='blue', alpha=0.3)\n",
    "    if not np.isnan(night_events['moonset']):\n",
    "        ax.axvline(mjd_to_datetime(night_events['moonset']), linestyle='-', color='red', alpha=0.3)\n",
    "    \n",
    "    colors = cc.glasbey_category10\n",
    "    # Assign distinct target sets with different colors\n",
    "    marker_colors =  {}\n",
    "    marker_style = {}\n",
    "    labels = {}\n",
    "    count = 0\n",
    "    if len(targets) > 0:\n",
    "        for sp in targets.science_program.unique():\n",
    "            if sp in programs:\n",
    "                for obs in targets.observation_reason.unique():\n",
    "                    marker_colors[obs] = colors[count]\n",
    "                    marker_style[obs] = 'o'\n",
    "                    labels[obs] = obs\n",
    "                    count += 1\n",
    "            else:\n",
    "                for sp in targets.science_program.unique():\n",
    "                    marker_colors[sp] = colors[count]\n",
    "                    marker_style[sp] = '^'\n",
    "                    labels[sp] = sp\n",
    "                    count += 1\n",
    "    \n",
    "    if len(targets) > 0:\n",
    "        visit_alpha = 0.7\n",
    "        for program in programs:\n",
    "            q = targets.query(\"science_program == @program\")\n",
    "            for sp in q.observation_reason.unique():\n",
    "                qq = q.query(\"observation_reason == @sp\")\n",
    "                label = sp\n",
    "                ax.plot(mjd_to_datetime(qq.mjd, 'tai'), qq.airmass, \n",
    "                        marker=marker_style[sp], linestyle='',\n",
    "                        color=marker_colors[sp], label=label,\n",
    "                        alpha=visit_alpha, markerfacecolor='none', zorder=3)\n",
    "        # then the remainder\n",
    "        q = targets.query(\"science_program not in @programs\")\n",
    "        for sp in q.science_program.unique():\n",
    "            qq = q.query(\"science_program == @sp\")\n",
    "            label = sp\n",
    "            ax.plot(mjd_to_datetime(qq.mjd, 'tai'), qq.airmass, \n",
    "                    marker=marker_style[sp], linestyle='',\n",
    "                    color=marker_colors[sp], markersize=9, label=label,\n",
    "                    alpha=1, markerfacecolor='none', zorder=4)\n",
    "\n",
    "    # Add actual visits\n",
    "    if len(initial_opsim) > 0:\n",
    "        q = initial_opsim.query(\"day_obs == @day_obs\")\n",
    "        for b in q.band.unique():\n",
    "            qq = q.query(\"band == @b\")\n",
    "            ax.plot(mjd_to_datetime(qq.observationStartMJD), qq.airmass, label=f\"{b} science\",\n",
    "                    alpha=0.6, marker='.', linestyle='', color=band_colors[b], zorder=0)\n",
    "        if len(q) > 0:\n",
    "            print(f\"Consdb reported {len(q)} visits. Simulation generated {len(targets)} visits.\")\n",
    "        \n",
    "    ax.legend(loc=(1.01, 0.0), ncol=2)\n",
    "    \n",
    "    x0 = night_events['sunset']+30/60/24\n",
    "    \n",
    "    ax.set_xlim(mjd_to_datetime(night_events['sunset']+30/60/24), \n",
    "             mjd_to_datetime(night_events['sunrise']-30/60/24))\n",
    "    ax_utc.set_xlim(mjd_to_datetime(night_events['sunset']+30/60/24, 'utc', timezone=tz_utc), \n",
    "             mjd_to_datetime(night_events['sunrise']-30/60/24, 'utc', timezone=tz_utc))\n",
    "    \n",
    "    ax.set_xlim(mjd_to_datetime(night_events['sunset']+30/60/24), \n",
    "             mjd_to_datetime(night_events['sunrise']-30/60/24))\n",
    "    ax_utc.set_xlim(mjd_to_datetime(night_events['sunset']+30/60/24, 'utc', timezone=tz_utc), \n",
    "             mjd_to_datetime(night_events['sunrise']-30/60/24, 'utc', timezone=tz_utc))\n",
    "    \n",
    "    # Set ticks relevant sides\n",
    "    ax.tick_params(axis=\"x\", bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "    ax_utc.tick_params(axis=\"x\", bottom=False, top=True, labelbottom=False, labeltop=True)\n",
    "    \n",
    "    # Rotate and align bottom ticklabels\n",
    "    plt.setp([tick.label1 for tick in ax.xaxis.get_major_ticks()], rotation=45,\n",
    "             ha=\"right\", va=\"center\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Rotate and align top ticklabels\n",
    "    plt.setp([tick.label2 for tick in ax_utc.xaxis.get_major_ticks()], rotation=45,\n",
    "             ha=\"left\", va=\"center\",rotation_mode=\"anchor\")\n",
    "    \n",
    "    plt.grid(True, alpha=0.2)\n",
    "    \n",
    "    plt.ylim(2.5, 0.9)\n",
    "    \n",
    "    ax.set_ylabel(\"Airmass\", fontsize=\"large\")\n",
    "    ax.set_xlabel(f\"Time ({tz})\", fontsize=\"large\")\n",
    "    ax_utc.set_xlabel(\"Time (UTC)\", fontsize='large')\n",
    "    _ = plt.ylabel(\"Airmass\", fontsize=\"large\")\n",
    "\n",
    "    print(f\"current UTC time {Time.now().iso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc2807-230e-48da-81e2-17b40bfc8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedview is noisy with warnings about things we don't need here \n",
    "# Make a spinny globe armillary sphere map of the simulated visits\n",
    "if sim_nights < 3:\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\") \n",
    "    \n",
    "        from schedview.compute.visits import add_coords_tuple\n",
    "        from schedview.plot.visitmap import create_visit_skymaps\n",
    "        from schedview.collect.visits import NIGHT_STACKERS\n",
    "        from schedview import DayObs\n",
    "        import bokeh.io\n",
    "        from bokeh.plotting import output_file\n",
    "\n",
    "        bokeh.io.output_notebook(hide_banner=True)\n",
    "        timezone = \"Chile/Continental\"\n",
    "        \n",
    "        oo = SchemaConverter().obs2opsim(observations).to_records()\n",
    "        for stacker in NIGHT_STACKERS:\n",
    "            oo = stacker.run(oo)\n",
    "        od = pd.DataFrame(oo)\n",
    "        \n",
    "        \n",
    "        print(f\"SIMULATION for {day_obs}\")\n",
    "        \n",
    "        if len(od):\n",
    "            od = add_coords_tuple(od)\n",
    "            vmap, vmap_data = create_visit_skymaps(\n",
    "                visits=od,\n",
    "                night_date=DayObs.from_date(day_obs).date,\n",
    "                timezone=timezone,\n",
    "                observatory=observatory,\n",
    "            )\n",
    "            bokeh.io.show(vmap)\n",
    "            # this would let you make a little stand-alone html map\n",
    "            # output_file(\"sim_visit.html\")\n",
    "            # bokeh.io.save(vmap)\n",
    "        else:\n",
    "            print(\"No visits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're running a sim in the past, compare the simulated seeing with the actual seeing.\n",
    "with_visits = True\n",
    "only_visits = False\n",
    "if day_obs <= today_dayobs:\n",
    "    print(\"Comparison of model vs. actual seeing - for past nights only\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "    if not only_visits:\n",
    "        dimm = endpoints['efd'].select_time_series(\"lsst.sal.DIMM.logevent_dimmMeasurement\", ['fwhm'], sunset, sunrise, index=1)\n",
    "        if len(dimm) > 0:\n",
    "            ax.plot(dimm.index, dimm.fwhm, linestyle='-', marker='.', linewidth=1, label=\"dimm1\")\n",
    "            print(f\"Dayobs {day_obs}\")\n",
    "            print(f\"DIMM mean FWHM {dimm.fwhm.mean():.2f}\")\n",
    "        dimm2 = endpoints['efd'].select_time_series(\"lsst.sal.DIMM.logevent_dimmMeasurement\", ['fwhm'], sunset, sunrise, index=2)\n",
    "        if len(dimm2) > 0:\n",
    "            ax.plot(dimm2.index, dimm2.fwhm, linestyle='-', marker='.',  linewidth=1, label=\"dimm2\")\n",
    "        ringss = endpoints['efd'].select_time_series(\"lsst.sal.ESS.logevent_ringssMeasurement\", ['fwhmFree', 'fwhmSector', 'fwhmScintillation'], sunset, sunrise)\n",
    "        if len(ringss) > 0:\n",
    "            ax.plot(ringss.index, ringss.fwhmFree, alpha=0.5, linestyle='-', marker='.',  label=\"ringss\")\n",
    "        # simulated dimm values\n",
    "        ax.plot(Time(observations['mjd'], format='mjd').to_datetime(), observations['FWHM_500'], linestyle=':', marker='.',  color='r', label=\"model fwhm500\")\n",
    "\n",
    "    if with_visits:\n",
    "        ax.plot(Time(observations['mjd'], format='mjd').to_datetime(), observations['FWHMeff'], 'r*', markersize=9, linestyle='', alpha=0.6, label=\"Simulated visit fwhm\")\n",
    "        q = initial_opsim.query(\"day_obs == @day_obs\")\n",
    "        ax.plot(Time(q.observationStartMJD, format='mjd').to_datetime(), q.seeingFwhmEff, 'k*', markersize=9, linestyle='', alpha=0.6, label=\"Measured visit fwhm\")\n",
    "    \n",
    "    ax.legend(loc=(1.01, 0.3))\n",
    "    \n",
    "    _ = ax.set_xlim(Time(targets.mjd - 0.5/24, format='mjd').to_datetime().min(), Time(targets.mjd + 0.5/24, format='mjd').to_datetime().max())\n",
    "    _ = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time between visits, for day_obs. Simulated and if in the past, also real visits.\n",
    "q = initial_opsim.query(\"day_obs == @day_obs\")\n",
    "obs_visit_gap = (q.observationStartMJD[1:].values - q.obs_end_mjd[:-1].values) * 60 * 60 * 24\n",
    "sim_visit_gap = (observations['mjd'][1:] - (observations['mjd'][:-1] + observations['visittime'][:-1]/60/60/24)) * 60 *60 *24\n",
    "bins = np.arange(0, 30, 0.5)\n",
    "_ = plt.hist(obs_visit_gap, bins=bins, alpha=0.6, label=\"observation\")\n",
    "_ = plt.hist(sim_visit_gap, bins=bins, alpha=0.6, label=\"sim\")\n",
    "plt.legend()\n",
    "_ = plt.xlabel(\"Time between visits (seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make quick map on-sky of sim visits from the simulation, if we only simulated a few nights.\n",
    "\n",
    "if sim_nights < 3:\n",
    "    print(\"Map of visits from this (sim, maybe also real) night only\")\n",
    "    snvis = {}\n",
    "    m_nvis = maf.CountMetric(col='mjd', metric_name = \"Nvisits\")\n",
    "    s = maf.HealpixSlicer(nside=64, lon_col='RA', lat_col='dec', rot_sky_pos_col_name = 'rotSkyPos', lat_lon_deg=False, verbose=False)\n",
    "    for b in ['all']:\n",
    "        constraint = f\"{b}\"\n",
    "        if b == 'all':\n",
    "            opsvis = pd.DataFrame(observations).to_records()\n",
    "        else:\n",
    "            opsvis = pd.DataFrame(observations).query(\"band == @b\").to_records()\n",
    "        snvis[b] = maf.MetricBundle(m_nvis, s, constraint)\n",
    "        g = maf.MetricBundleGroup({f'single night nvisits {b}': snvis[b]}, None)\n",
    "        if len(opsvis) > 0:\n",
    "            g.run_current(constraint, opsvis)\n",
    "\n",
    "    background = plot.get_background(nside=64)\n",
    "    mval = snvis['all'].metric_values\n",
    "    vmax = np.percentile(mval.compressed(), 95)\n",
    "    alpha = np.where(np.isnan(background), 0, background)\n",
    "    alpha = np.where(alpha> 0.5, 0.5, alpha)\n",
    "    alpha = np.where(mval.filled(0) > 0, 1, alpha)\n",
    "    plot.hp_moll(mval.filled(0), alpha=alpha, vmin=0, vmax=vmax, label='Simulated night')\n",
    "\n",
    "# Make map on-sky of real visits\n",
    "if sim_nights < 3 and day_obs <= today_dayobs:\n",
    "    vnvis = {}\n",
    "    m_nvis = maf.CountMetric(col='observationStartMJD', metric_name = \"Nvisits\")\n",
    "    s = maf.HealpixSlicer(nside=64, lon_col='fieldRA', lat_col='fieldDec', rot_sky_pos_col_name = 'rotSkyPos', lat_lon_deg=True, verbose=False)\n",
    "    for b in ['all']:\n",
    "        constraint = f\"{b}\"\n",
    "        if b == 'all':\n",
    "            opsvis = pd.DataFrame(initial_opsim.query(\"day_obs == @day_obs\")).to_records()\n",
    "        else:\n",
    "            opsvis = pd.DataFrame(observations).query(\"day_obs == @day_obs and band == @b\").to_records()\n",
    "        vnvis[b] = maf.MetricBundle(m_nvis, s, constraint)\n",
    "        g = maf.MetricBundleGroup({f'single night nvisits {b}': vnvis[b]}, None)\n",
    "        if len(opsvis) > 0:\n",
    "            g.run_current(constraint, opsvis)\n",
    "    if vnvis['all'].metric_values is not None:\n",
    "        mval = vnvis['all'].metric_values\n",
    "        vmax = np.percentile(mval.compressed(), 95)\n",
    "        plot.hp_moll(mval.filled(0), alpha=alpha, vmin=0, vmax=vmax, label='Consdb night')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform observations to opsim format, maybe add initial visits as well.\n",
    "if sim_nights == 1:\n",
    "    print(\"## All plots or tables below this point contain simulated visits only\")\n",
    "    # Only new observations?\n",
    "    obsdf = lsst_support.save_opsim(observatory, observations, initial_opsim=None, filename=None)\n",
    "    sim_only = True\n",
    "else:\n",
    "    print(\"## All plots or tables below this point contain past (real visit) history plus simulated visits\")\n",
    "    # All observations?\n",
    "    obsdf = lsst_support.save_opsim(observatory, observations, initial_opsim=initial_opsim, filename=None)\n",
    "    sim_only = False\n",
    "# dayobs is very useful .. maybe we should add to opsim outputs.\n",
    "def add_dayobs(x):\n",
    "    mjdfloor = Time(np.floor(x.observationStartMJD - 0.5) + 0.5, format=\"mjd\", scale=\"tai\")\n",
    "    return rn_dayobs.day_obs_str_to_int(mjdfloor.isot.split(\"T\")[0])\n",
    "\n",
    "obsdf[\"day_obs\"] = obsdf.apply(add_dayobs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at DDF visits in obsdf (maybe all, maybe sim only)\n",
    "ddf_visits = obsdf.query(\"observation_reason.str.contains('DD') or observation_reason.str.contains('ddf')\").copy()\n",
    "if len(ddf_visits) > 0:\n",
    "    print(\"n visits per band\")\n",
    "    ddf_visits.loc[:, 'observation_reason'] = ddf_visits.observation_reason.str.lower()\n",
    "    ss = ddf_visits.groupby([\"observation_reason\", \"band\"]).agg({'observationStartMJD': 'count'})\n",
    "    ss = ss.reset_index('band').pivot(columns=[\"band\"]).droplevel(0, axis=1)\n",
    "    ss['all'] = ss.sum(axis=1)\n",
    "    order = ['u', 'g', 'r', 'i', 'z', 'y', 'all']    \n",
    "    display(ss.query(\"observation_reason.str.contains('dd')\")[[o for o in order if o in ss.columns]])\n",
    "    \n",
    "    print(\"n days per band\")\n",
    "    ss = ddf_visits.groupby([\"observation_reason\", \"band\"]).agg({'day_obs': 'nunique'})\n",
    "    ss = ss.reset_index('band').pivot(columns=[\"band\"]).droplevel(0, axis=1)\n",
    "    ss['all'] = ddf_visits.groupby(\"observation_reason\").agg({'day_obs': 'nunique'})\n",
    "    display(ss.query(\"observation_reason.str.contains('dd')\")[[o for o in order if o in ss]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate nice static plots\n",
    "run_calc = True\n",
    "if run_calc:\n",
    "    nvisits = {}\n",
    "    coadd = {}\n",
    "    m_nvis = maf.CountMetric(col='observationStartMJD', metric_name = \"Nvisits\")\n",
    "    m_coadd = maf.Coaddm5Metric(m5_col='fiveSigmaDepth')\n",
    "    s = maf.HealpixSlicer(nside=64, lon_col='fieldRA', lat_col='fieldDec', rot_sky_pos_col_name = 'rotSkyPos', verbose=False)\n",
    "    for b in ['u', 'g', 'r', 'i', 'z', 'y', 'all']:\n",
    "        constraint = f\"{b}\"\n",
    "        if b == 'all':\n",
    "            opsvis = obsdf.to_records()\n",
    "        else:\n",
    "            opsvis = obsdf.query(\"band == @b\").to_records()\n",
    "        nvisits[b] = maf.MetricBundle(m_nvis, s, constraint)\n",
    "        coadd[b] = maf.MetricBundle(m_coadd, s, constraint)\n",
    "        g = maf.MetricBundleGroup({f'nvisits {b}': nvisits[b], f'coadd {b}': coadd[b]}, None, save_early=False)\n",
    "        if len(opsvis) > 0:\n",
    "            g.run_current(constraint, opsvis)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sim_only:\n",
    "    print(\"Simulated visits only\")\n",
    "else:\n",
    "    print(\"Simulated plus previous real visits\")\n",
    "    \n",
    "background = plot.get_background(nside=64)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(16, 10),)\n",
    "axdict = {\"u\": ax[0][0], \"g\": ax[0][1], \"r\": ax[0][2],\n",
    "          \"i\": ax[1][0], \"z\": ax[1][1], \"y\": ax[1][2], \"all\": None}\n",
    "for b in [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]:\n",
    "    if nvisits[b].metric_values is None:\n",
    "        continue\n",
    "    if len(nvisits[b].metric_values.compressed()) > 1:\n",
    "        vmax = np.percentile(nvisits[b].metric_values.compressed(), 95)\n",
    "    else:\n",
    "        vmax = None\n",
    "    label_dec = False\n",
    "    if b == 'u' or b == 'i':\n",
    "        label_dec = True\n",
    "    fig = plot.make_plot(nvisits[b], background=background, proj='McBryde', vmax=vmax, ax=axdict[b], title=f\"LSSTCam band {b}\", label_dec=label_dec)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(out_dir, f\"lsstcam_nvisits_band.png\"), bbox_inches='tight')\n",
    "\n",
    "vmax = np.percentile(nvisits['all'].metric_values.compressed(), 95)\n",
    "fig = plot.make_plot(nvisits['all'], background=background, proj='mcbryde', vmin=None, vmax=vmax, ax=None, title=f\"LSSTCam visits\")\n",
    "#fig.savefig(os.path.join(out_dir, f\"lsstcam_nvisits.png\"), bbox_inches='tight')\n",
    "fig = plot.make_plot(nvisits['all'], background=background, proj='laea', vmin=None, vmax=vmax, ax=None, title=f\"LSSTCam visits\")\n",
    "#fig.savefig(os.path.join(out_dir, f\"lsstcam_laea_nvisits.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
